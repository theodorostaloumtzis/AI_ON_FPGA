{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ee6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 00:10:37.719712: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-08 00:10:37.778484: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-08 00:10:37.780413: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-04-08 00:10:37.780419: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-04-08 00:10:38.094638: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-04-08 00:10:38.094675: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-04-08 00:10:38.094679: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Input, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.layers import Activation\n",
    "import time\n",
    "import os\n",
    "os.environ['XILINX_VITIS'] = '/tools/Xilinx/Vitis/2024.2'\n",
    "os.environ['PATH'] = '/tools/Xilinx/Vivado/2020.1/bin:' + os.environ['PATH']\n",
    "os.environ['PATH'] = '/tools/Xilinx/Vitis_HLS/2024.2/bin:' + os.environ['PATH']\n",
    "from model_utils import save_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f706cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 00:10:38.805005: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2025-04-08 00:10:38.805021: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-04-08 00:10:38.805031: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (theodoros-MS-7D75): /proc/driver/nvidia/version does not exist\n",
      "2025-04-08 00:10:38.805218: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to [0, 1]\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test  = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Reshape to add channel dimension (28x28x1)\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_test  = x_test.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test  = to_categorical(y_test, 10)\n",
    "\n",
    "# Split off a validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create tf.data.Dataset objects (optional but recommended for performance)\n",
    "batch_size = 1024\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(batch_size)\n",
    "val_data   = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size)\n",
    "test_data  = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "\n",
    "# Optional: set number of epochs\n",
    "n_epochs = 10\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04d348d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding convolutional block 0 with N=16 filters\n",
      "Adding convolutional block 1 with N=16 filters\n",
      "Adding convolutional block 2 with N=24 filters\n",
      "Adding dense block 0 with N=42 neurons\n",
      "Adding dense block 1 with N=64 neurons\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization\n",
    "\n",
    "filters_per_conv_layer = [16, 16, 24]\n",
    "neurons_per_dense_layer = [42, 64]\n",
    "\n",
    "x = x_in = Input(input_shape)\n",
    "\n",
    "for i, f in enumerate(filters_per_conv_layer):\n",
    "    print(('Adding convolutional block {} with N={} filters').format(i, f))\n",
    "    x = Conv2D(\n",
    "        int(f),\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=l1(0.0001),\n",
    "        use_bias=False,\n",
    "        name='conv_{}'.format(i),\n",
    "    )(x)\n",
    "    x = BatchNormalization(name='bn_conv_{}'.format(i))(x)\n",
    "    x = Activation('relu', name='conv_act_%i' % i)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='pool_{}'.format(i))(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "for i, n in enumerate(neurons_per_dense_layer):\n",
    "    print(('Adding dense block {} with N={} neurons').format(i, n))\n",
    "    x = Dense(n, kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001), name='dense_%i' % i, use_bias=False)(x)\n",
    "    x = BatchNormalization(name='bn_dense_{}'.format(i))(x)\n",
    "    x = Activation('relu', name='dense_act_%i' % i)(x)\n",
    "x = Dense(int(n_classes), name='output_dense')(x)\n",
    "x_out = Activation('softmax', name='output_softmax')(x)\n",
    "\n",
    "baseline_model = Model(inputs=[x_in], outputs=[x_out], name='keras_baseline')\n",
    "\n",
    "LOSS = tf.keras.losses.CategoricalCrossentropy()\n",
    "OPTIMIZER = tf.keras.optimizers.legacy.Adam(learning_rate=3e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "\n",
    "baseline_model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "# Copy the model to a new variable\n",
    "cloned_model = tf.keras.models.clone_model(baseline_model)\n",
    "cloned_model = tf.keras.models.clone_model(baseline_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa2d5223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "53/53 - 2s - loss: 0.7902 - accuracy: 0.8021 - val_loss: 1.0894 - val_accuracy: 0.7868 - 2s/epoch - 30ms/step\n",
      "Epoch 2/10\n",
      "53/53 - 1s - loss: 0.2408 - accuracy: 0.9576 - val_loss: 1.4653 - val_accuracy: 0.5740 - 1s/epoch - 20ms/step\n",
      "Epoch 3/10\n",
      "53/53 - 1s - loss: 0.1882 - accuracy: 0.9718 - val_loss: 1.6147 - val_accuracy: 0.5325 - 1s/epoch - 20ms/step\n",
      "Epoch 4/10\n",
      "53/53 - 1s - loss: 0.1633 - accuracy: 0.9783 - val_loss: 1.1523 - val_accuracy: 0.6440 - 1s/epoch - 20ms/step\n",
      "Epoch 5/10\n",
      "53/53 - 1s - loss: 0.1458 - accuracy: 0.9819 - val_loss: 0.9740 - val_accuracy: 0.7042 - 1s/epoch - 19ms/step\n",
      "Epoch 6/10\n",
      "53/53 - 1s - loss: 0.1339 - accuracy: 0.9848 - val_loss: 0.4856 - val_accuracy: 0.8608 - 1s/epoch - 19ms/step\n",
      "Epoch 7/10\n",
      "53/53 - 1s - loss: 0.1251 - accuracy: 0.9865 - val_loss: 0.3726 - val_accuracy: 0.9080 - 1s/epoch - 19ms/step\n",
      "Epoch 8/10\n",
      "53/53 - 1s - loss: 0.1152 - accuracy: 0.9878 - val_loss: 0.2097 - val_accuracy: 0.9585 - 1s/epoch - 19ms/step\n",
      "Epoch 9/10\n",
      "53/53 - 1s - loss: 0.1089 - accuracy: 0.9887 - val_loss: 0.2008 - val_accuracy: 0.9567 - 1s/epoch - 19ms/step\n",
      "Epoch 10/10\n",
      "53/53 - 1s - loss: 0.1026 - accuracy: 0.9896 - val_loss: 0.1970 - val_accuracy: 0.9595 - 1s/epoch - 19ms/step\n",
      "bn_conv_0            is normal keras bn layer\n",
      "bn_conv_1            is normal keras bn layer\n",
      "bn_conv_2            is normal keras bn layer\n",
      "bn_dense_0           is normal keras bn layer\n",
      "bn_dense_1           is normal keras bn layer\n",
      "\n",
      "10/10 - 0s - loss: 0.1868 - accuracy: 0.9646 - 51ms/epoch - 5ms/step\n",
      "Test loss: 0.18676555156707764\n",
      "Test accuracy: 0.9646000266075134\n",
      "✅ Model saved to: models/keras_baseline.h5\n"
     ]
    }
   ],
   "source": [
    "from qkeras.autoqkeras import *\n",
    "from qkeras import *\n",
    "\n",
    "# Compile the cloned model\n",
    "cloned_model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "# Train the cloned model\n",
    "cloned_model.fit(train_data, epochs=n_epochs, validation_data=val_data, verbose=2)\n",
    "\n",
    "print_qmodel_summary(cloned_model)\n",
    "\n",
    "# Evaluate the cloned model\n",
    "loss, accuracy = cloned_model.evaluate(test_data, verbose=2)\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {accuracy}\")\n",
    "# Save the model\n",
    "model_dir = \"models\"\n",
    "model_name = \"keras_baseline\"\n",
    "model_path = os.path.join(model_dir, model_name)\n",
    "save_model(cloned_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb0fb744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'models/keras_baseline.h5' at http://localhost:42315\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:42315\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7bd5635575e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from netron_embed import view_model\n",
    "\n",
    "# View your model inline (any format: .onnx, .h5, .pb, etc.)\n",
    "view_model(model_path+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1073058e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/theodoros/Documents/AI_ON_FPGA/.venv/lib/python3.10/site-packages/qkeras/qtools/qgraph.py:189: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "{\n",
      "    \"source_quantizers\": [\n",
      "        {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 6,\n",
      "            \"is_signed\": true\n",
      "        }\n",
      "    ],\n",
      "    \"conv_0\": {\n",
      "        \"layer_type\": \"Conv2D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 16,\n",
      "                \"int_bits\": 6,\n",
      "                \"is_signed\": true\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                3,\n",
      "                1,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                26,\n",
      "                26,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 97344\n",
      "    },\n",
      "    \"bn_conv_0\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                26,\n",
      "                26,\n",
      "                16\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"conv_act_0\": {\n",
      "        \"layer_type\": \"Activation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                26,\n",
      "                26,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 10816\n",
      "    },\n",
      "    \"pool_0\": {\n",
      "        \"layer_type\": \"MaxPooling2D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                13,\n",
      "                13,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 10816\n",
      "    },\n",
      "    \"conv_1\": {\n",
      "        \"layer_type\": \"Conv2D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                3,\n",
      "                16,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                11,\n",
      "                11,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 278784\n",
      "    },\n",
      "    \"bn_conv_1\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                11,\n",
      "                11,\n",
      "                16\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"conv_act_1\": {\n",
      "        \"layer_type\": \"Activation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                11,\n",
      "                11,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 1936\n",
      "    },\n",
      "    \"pool_1\": {\n",
      "        \"layer_type\": \"MaxPooling2D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                5,\n",
      "                5,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 1936\n",
      "    },\n",
      "    \"conv_2\": {\n",
      "        \"layer_type\": \"Conv2D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                3,\n",
      "                16,\n",
      "                24\n",
      "            ]\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                3,\n",
      "                3,\n",
      "                24\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 31104\n",
      "    },\n",
      "    \"bn_conv_2\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                3,\n",
      "                3,\n",
      "                24\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"conv_act_2\": {\n",
      "        \"layer_type\": \"Activation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                3,\n",
      "                3,\n",
      "                24\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 216\n",
      "    },\n",
      "    \"pool_2\": {\n",
      "        \"layer_type\": \"MaxPooling2D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1,\n",
      "                1,\n",
      "                24\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 216\n",
      "    },\n",
      "    \"flatten\": {\n",
      "        \"layer_type\": \"Flatten\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                24\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 24\n",
      "    },\n",
      "    \"dense_0\": {\n",
      "        \"layer_type\": \"Dense\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                24,\n",
      "                42\n",
      "            ]\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                42\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 1008\n",
      "    },\n",
      "    \"bn_dense_0\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                42\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"dense_act_0\": {\n",
      "        \"layer_type\": \"Activation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                42\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 42\n",
      "    },\n",
      "    \"dense_1\": {\n",
      "        \"layer_type\": \"Dense\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                42,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 2688\n",
      "    },\n",
      "    \"bn_dense_1\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                64\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"dense_act_1\": {\n",
      "        \"layer_type\": \"Activation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 64\n",
      "    },\n",
      "    \"output_dense\": {\n",
      "        \"layer_type\": \"Dense\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                64,\n",
      "                10\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": 10\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                10\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 640\n",
      "    },\n",
      "    \"output_softmax\": {\n",
      "        \"layer_type\": \"Activation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                10\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 10\n",
      "    }\n",
      "}\n",
      "{'bn_conv_0': {'energy': {'inputs': 0.0,\n",
      "                          'op_cost': 23795.2,\n",
      "                          'outputs': 0.0,\n",
      "                          'parameters': 0.0},\n",
      "               'total': 0.0},\n",
      " 'bn_conv_1': {'energy': {'inputs': 0.0,\n",
      "                          'op_cost': 4259.2,\n",
      "                          'outputs': 0.0,\n",
      "                          'parameters': 0.0},\n",
      "               'total': 0.0},\n",
      " 'bn_conv_2': {'energy': {'inputs': 0.0,\n",
      "                          'op_cost': 475.2,\n",
      "                          'outputs': 0.0,\n",
      "                          'parameters': 0.0},\n",
      "               'total': 0.0},\n",
      " 'bn_dense_0': {'energy': {'inputs': 0.0,\n",
      "                           'op_cost': 92.4,\n",
      "                           'outputs': 0.0,\n",
      "                           'parameters': 0.0},\n",
      "                'total': 0.0},\n",
      " 'bn_dense_1': {'energy': {'inputs': 0.0,\n",
      "                           'op_cost': 140.8,\n",
      "                           'outputs': 0.0,\n",
      "                           'parameters': 0.0},\n",
      "                'total': 0.0},\n",
      " 'conv_0': {'energy': {'inputs': 745.54,\n",
      "                       'op_cost': 146016.0,\n",
      "                       'outputs': 0.0,\n",
      "                       'parameters': 0.0},\n",
      "            'total': 146761.54},\n",
      " 'conv_1': {'energy': {'inputs': 0.0,\n",
      "                       'op_cost': 418176.0,\n",
      "                       'outputs': 0.0,\n",
      "                       'parameters': 0.0},\n",
      "            'total': 418176.0},\n",
      " 'conv_2': {'energy': {'inputs': 0.0,\n",
      "                       'op_cost': 46656.0,\n",
      "                       'outputs': 0.0,\n",
      "                       'parameters': 0.0},\n",
      "            'total': 46656.0},\n",
      " 'conv_act_0': {'energy': {'inputs': 0.0,\n",
      "                           'op_cost': 0.0,\n",
      "                           'outputs': 0.0,\n",
      "                           'parameters': 0.0},\n",
      "                'total': 0.0},\n",
      " 'conv_act_1': {'energy': {'inputs': 0.0,\n",
      "                           'op_cost': 0.0,\n",
      "                           'outputs': 0.0,\n",
      "                           'parameters': 0.0},\n",
      "                'total': 0.0},\n",
      " 'conv_act_2': {'energy': {'inputs': 0.0,\n",
      "                           'op_cost': 0.0,\n",
      "                           'outputs': 0.0,\n",
      "                           'parameters': 0.0},\n",
      "                'total': 0.0},\n",
      " 'dense_0': {'energy': {'inputs': 0.0,\n",
      "                        'op_cost': 1512.0,\n",
      "                        'outputs': 0.0,\n",
      "                        'parameters': 0.0},\n",
      "             'total': 1512.0},\n",
      " 'dense_1': {'energy': {'inputs': 0.0,\n",
      "                        'op_cost': 4032.0,\n",
      "                        'outputs': 0.0,\n",
      "                        'parameters': 0.0},\n",
      "             'total': 4032.0},\n",
      " 'dense_act_0': {'energy': {'inputs': 0.0,\n",
      "                            'op_cost': 0.0,\n",
      "                            'outputs': 0.0,\n",
      "                            'parameters': 0.0},\n",
      "                 'total': 0.0},\n",
      " 'dense_act_1': {'energy': {'inputs': 0.0,\n",
      "                            'op_cost': 0.0,\n",
      "                            'outputs': 0.0,\n",
      "                            'parameters': 0.0},\n",
      "                 'total': 0.0},\n",
      " 'flatten': {'energy': {'inputs': 0.0,\n",
      "                        'op_cost': 0.0,\n",
      "                        'outputs': 0.0,\n",
      "                        'parameters': 0.0},\n",
      "             'total': 0.0},\n",
      " 'output_dense': {'energy': {'inputs': 0.0,\n",
      "                             'op_cost': 960.0,\n",
      "                             'outputs': 0.0,\n",
      "                             'parameters': 0.0},\n",
      "                  'total': 960.0},\n",
      " 'output_softmax': {'energy': {'inputs': 0.0,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 11.41,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 11.41},\n",
      " 'pool_0': {'energy': {'inputs': 0.0,\n",
      "                       'op_cost': 0.0,\n",
      "                       'outputs': 0.0,\n",
      "                       'parameters': 0.0},\n",
      "            'total': 0.0},\n",
      " 'pool_1': {'energy': {'inputs': 0.0,\n",
      "                       'op_cost': 0.0,\n",
      "                       'outputs': 0.0,\n",
      "                       'parameters': 0.0},\n",
      "            'total': 0.0},\n",
      " 'pool_2': {'energy': {'inputs': 0.0,\n",
      "                       'op_cost': 0.0,\n",
      "                       'outputs': 0.0,\n",
      "                       'parameters': 0.0},\n",
      "            'total': 0.0}}\n",
      "\n",
      "Total energy: 0.618108 uJ\n"
     ]
    }
   ],
   "source": [
    "from qkeras import print_qstats\n",
    "\n",
    "# for automatic quantization\n",
    "import pprint\n",
    "from qkeras.autoqkeras import *\n",
    "from qkeras import *\n",
    "from qkeras.utils import model_quantize\n",
    "\n",
    "from qkeras.qtools import run_qtools\n",
    "from qkeras.qtools import settings as qtools_settings\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "from qkeras import quantized_bits\n",
    "from qkeras import QDense, QActivation\n",
    "\n",
    "q = run_qtools.QTools(\n",
    "    baseline_model,\n",
    "    process=\"horowitz\",\n",
    "    source_quantizers=[quantized_bits(16, 5, 1)],\n",
    "    is_inference=True,\n",
    "    weights_path=None,\n",
    "    keras_quantizer=\"fp16\",\n",
    "    keras_accumulator=\"fp16\",\n",
    "    for_reference=False,\n",
    ")\n",
    "q.qtools_stats_print()\n",
    "\n",
    "energy_dict = q.pe(\n",
    "    weights_on_memory=\"fixed\", activations_on_memory=\"fixed\", min_sram_size=8 * 16 * 1024 * 1024, rd_wr_on_io=False\n",
    ")\n",
    "\n",
    "# get stats of energy distribution in each layer\n",
    "energy_profile = q.extract_energy_profile(qtools_settings.cfg.include_energy, energy_dict)\n",
    "# extract sum of energy of each layer according to the rule specified in\n",
    "# qtools_settings.cfg.include_energy\n",
    "total_energy = q.extract_energy_sum(qtools_settings.cfg.include_energy, energy_dict)\n",
    "\n",
    "pprint.pprint(energy_profile)\n",
    "print()\n",
    "\n",
    "print(\"Total energy: {:.6f} uJ\".format(total_energy / 1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d665e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the quantizers we'll test in the bayesian optimization\n",
    "quantization_config = {\n",
    "    \"kernel\": {\n",
    "        \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n",
    "        \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "        \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n",
    "        \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n",
    "    },\n",
    "    \"bias\": {\n",
    "        \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n",
    "        \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "        \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n",
    "        \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n",
    "    },\n",
    "    \"activation\": {\n",
    "        \"quantized_relu(3,1)\": 3,\n",
    "        \"quantized_relu(4,2)\": 4,\n",
    "        \"quantized_relu(8,2)\": 8,\n",
    "        \"quantized_relu(8,4)\": 8,\n",
    "        \"quantized_relu(16,6)\": 16,\n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n",
    "        \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "        \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n",
    "        \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# These are the layer types we will quantize\n",
    "limit = {\n",
    "    \"conv\": [8, 8, 16],\n",
    "    \"dense\": [8, 8, 16],\n",
    "    \"act\": [16]\n",
    "}\n",
    "\n",
    "\n",
    "# Use this if you want to minimize the model bit size\n",
    "goal_bits = {\n",
    "    \"type\": \"bits\",\n",
    "    \"params\": {\n",
    "        \"delta_p\": 2.0,  # We tolerate up to a +8% accuracy change\n",
    "        \"delta_n\": 2.0,  # We tolerate down to a -5% accuracy change\n",
    "        \"rate\": 2.0,  # We want a x2 times smaller model\n",
    "        \"stress\": 1.0,  # Force the reference model size to be smaller by setting stress<1\n",
    "        \"input_bits\": 8,\n",
    "        \"output_bits\": 8,\n",
    "        \"ref_bits\": 8,\n",
    "        \"config\": {\"default\": [\"parameters\", \"activations\"]},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Use this if you want to minimize the model energy consumption\n",
    "goal_energy = {\n",
    "    \"type\": \"energy\",\n",
    "    \"params\": {\n",
    "        \"delta_p\": 8.0,\n",
    "        \"delta_n\": 8.0,\n",
    "        \"rate\": 2.0,\n",
    "        \"stress\": 1.0,\n",
    "        \"process\": \"horowitz\",\n",
    "        \"parameters_on_memory\": [\"sram\", \"sram\"],\n",
    "        \"activations_on_memory\": [\"sram\", \"sram\"],\n",
    "        \"rd_wr_on_io\": [False, False],\n",
    "        \"min_sram_size\": [0, 0],\n",
    "        \"source_quantizers\": [\"fp32\"],\n",
    "        \"reference_internal\": \"int8\",\n",
    "        \"reference_accumulator\": \"int32\",\n",
    "    },\n",
    "}\n",
    "\n",
    "run_config = {\n",
    "    \"goal\": goal_bits,\n",
    "    \"quantization_config\": quantization_config,\n",
    "    \"learning_rate_optimizer\": False,\n",
    "    \"transfer_weights\": False,  # Randomely initialize weights\n",
    "    \"mode\": \"bayesian\",  # This can be bayesian,random,hyperband\n",
    "    \"seed\": 42,\n",
    "    \"limit\": limit,\n",
    "    #\"tune_filters\": \"layer\",\n",
    "    #\"tune_filters_exceptions\": \"^output\",\n",
    "    \"tune_filters\": \"none\",\n",
    "    \"tune_filters_exceptions\": \"\",  \n",
    "    \"distribution_strategy\": None,\n",
    "    \"max_trials\": 5,  # Let's just do 5 trials for this demonstrator, ideally you should do as many as possible\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e90f39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limit configuration:{\"conv\": [8, 8, 16], \"dense\": [8, 8, 16], \"act\": [16]}\n",
      "learning_rate: 0.003000000026077032\n",
      "Model: \"keras_baseline\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv_0 (QConv2D)            (None, 26, 26, 16)        144       \n",
      "                                                                 \n",
      " bn_conv_0 (BatchNormalizati  (None, 26, 26, 16)       64        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_act_0 (QActivation)    (None, 26, 26, 16)        0         \n",
      "                                                                 \n",
      " pool_0 (MaxPooling2D)       (None, 13, 13, 16)        0         \n",
      "                                                                 \n",
      " conv_1 (QConv2D)            (None, 11, 11, 16)        2304      \n",
      "                                                                 \n",
      " bn_conv_1 (BatchNormalizati  (None, 11, 11, 16)       64        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_act_1 (QActivation)    (None, 11, 11, 16)        0         \n",
      "                                                                 \n",
      " pool_1 (MaxPooling2D)       (None, 5, 5, 16)          0         \n",
      "                                                                 \n",
      " conv_2 (QConv2D)            (None, 3, 3, 24)          3456      \n",
      "                                                                 \n",
      " bn_conv_2 (BatchNormalizati  (None, 3, 3, 24)         96        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_act_2 (QActivation)    (None, 3, 3, 24)          0         \n",
      "                                                                 \n",
      " pool_2 (MaxPooling2D)       (None, 1, 1, 24)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 24)                0         \n",
      "                                                                 \n",
      " dense_0 (QDense)            (None, 42)                1008      \n",
      "                                                                 \n",
      " bn_dense_0 (BatchNormalizat  (None, 42)               168       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_act_0 (QActivation)   (None, 42)                0         \n",
      "                                                                 \n",
      " dense_1 (QDense)            (None, 64)                2688      \n",
      "                                                                 \n",
      " bn_dense_1 (BatchNormalizat  (None, 64)               256       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_act_1 (QActivation)   (None, 64)                0         \n",
      "                                                                 \n",
      " output_dense (Dense)        (None, 10)                650       \n",
      "                                                                 \n",
      " output_softmax (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,898\n",
      "Trainable params: 10,574\n",
      "Non-trainable params: 324\n",
      "_________________________________________________________________\n",
      "stats: delta_p=0.02 delta_n=0.02 rate=2.0 trial_size=72566 reference_size=195536\n",
      "       delta=2.86%\n",
      "       a_bits=45574/110944 (-58.92%) p_bits=26992/84592 (-68.09%)\n",
      "       total=72566/195536 (-62.89%)\n",
      "conv_0               f=16 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_conv_0            is normal keras bn layer\n",
      "conv_act_0           quantized_relu(3,1)\n",
      "conv_1               f=16 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_conv_1            is normal keras bn layer\n",
      "conv_act_1           quantized_relu(3,1)\n",
      "conv_2               f=24 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_conv_2            is normal keras bn layer\n",
      "conv_act_2           quantized_relu(3,1)\n",
      "dense_0              u=42 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_dense_0           is normal keras bn layer\n",
      "dense_act_0          quantized_relu(3,1)\n",
      "dense_1              u=64 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_dense_1           is normal keras bn layer\n",
      "dense_act_1          quantized_relu(3,1)\n",
      "\n",
      "Search space summary\n",
      "Default search space size: 4\n",
      "conv_kernel_quantizer (Choice)\n",
      "{'default': 'quantized_bits(2,0,1,alpha=1.0)', 'conditions': [], 'values': ['quantized_bits(2,0,1,alpha=1.0)', 'quantized_bits(4,0,1,alpha=1.0)', 'quantized_bits(6,0,1,alpha=1.0)', 'quantized_bits(8,0,1,alpha=1.0)'], 'ordered': False}\n",
      "dense_kernel_quantizer (Choice)\n",
      "{'default': 'quantized_bits(2,0,1,alpha=1.0)', 'conditions': [], 'values': ['quantized_bits(2,0,1,alpha=1.0)', 'quantized_bits(4,0,1,alpha=1.0)', 'quantized_bits(6,0,1,alpha=1.0)', 'quantized_bits(8,0,1,alpha=1.0)'], 'ordered': False}\n",
      "conv_activation_quantizer (Choice)\n",
      "{'default': 'quantized_relu(3,1)', 'conditions': [], 'values': ['quantized_relu(3,1)', 'quantized_relu(4,2)', 'quantized_relu(8,2)', 'quantized_relu(8,4)', 'quantized_relu(16,6)'], 'ordered': False}\n",
      "dense_activation_quantizer (Choice)\n",
      "{'default': 'quantized_relu(3,1)', 'conditions': [], 'values': ['quantized_relu(3,1)', 'quantized_relu(4,2)', 'quantized_relu(8,2)', 'quantized_relu(8,4)', 'quantized_relu(16,6)'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "from qkeras.autoqkeras import AutoQKeras\n",
    "autoqk = AutoQKeras(\n",
    "    model=baseline_model,\n",
    "    output_dir=\"autoqk_results\",\n",
    "    **run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f86536d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 44s]\n",
      "val_score: 0.9914345741271973\n",
      "\n",
      "Best val_score So Far: 0.9914345741271973\n",
      "Total elapsed time: 00h 02m 12s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "space = autoqk.tuner.oracle.get_space()\n",
    "print(\"\\n🔍 Registered hyperparameters:\")\n",
    "for hp in space.space:\n",
    "    print(f\"• {hp.name}: {hp.values}\")\n",
    "\n",
    "\n",
    "autoqk.fit(\n",
    "    x=train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=15  # Or however many you want for each trial\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6d5180d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.003000000026077032\n",
      "Model: \"keras_baseline\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv_0 (QConv2D)            (None, 26, 26, 16)        144       \n",
      "                                                                 \n",
      " bn_conv_0 (BatchNormalizati  (None, 26, 26, 16)       64        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_act_0 (QActivation)    (None, 26, 26, 16)        0         \n",
      "                                                                 \n",
      " pool_0 (MaxPooling2D)       (None, 13, 13, 16)        0         \n",
      "                                                                 \n",
      " conv_1 (QConv2D)            (None, 11, 11, 16)        2304      \n",
      "                                                                 \n",
      " bn_conv_1 (BatchNormalizati  (None, 11, 11, 16)       64        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_act_1 (QActivation)    (None, 11, 11, 16)        0         \n",
      "                                                                 \n",
      " pool_1 (MaxPooling2D)       (None, 5, 5, 16)          0         \n",
      "                                                                 \n",
      " conv_2 (QConv2D)            (None, 3, 3, 24)          3456      \n",
      "                                                                 \n",
      " bn_conv_2 (BatchNormalizati  (None, 3, 3, 24)         96        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_act_2 (QActivation)    (None, 3, 3, 24)          0         \n",
      "                                                                 \n",
      " pool_2 (MaxPooling2D)       (None, 1, 1, 24)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 24)                0         \n",
      "                                                                 \n",
      " dense_0 (QDense)            (None, 42)                1008      \n",
      "                                                                 \n",
      " bn_dense_0 (BatchNormalizat  (None, 42)               168       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_act_0 (QActivation)   (None, 42)                0         \n",
      "                                                                 \n",
      " dense_1 (QDense)            (None, 64)                2688      \n",
      "                                                                 \n",
      " bn_dense_1 (BatchNormalizat  (None, 64)               256       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_act_1 (QActivation)   (None, 64)                0         \n",
      "                                                                 \n",
      " output_dense (Dense)        (None, 10)                650       \n",
      "                                                                 \n",
      " output_softmax (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,898\n",
      "Trainable params: 10,574\n",
      "Non-trainable params: 324\n",
      "_________________________________________________________________\n",
      "stats: delta_p=0.02 delta_n=0.02 rate=2.0 trial_size=109680 reference_size=195536\n",
      "       delta=1.67%\n",
      "       a_bits=59072/110944 (-46.76%) p_bits=50608/84592 (-40.17%)\n",
      "       total=109680/195536 (-43.91%)\n",
      "conv_0               f=16 quantized_bits(6,0,1,alpha=1.0) \n",
      "bn_conv_0            is normal keras bn layer\n",
      "conv_act_0           quantized_relu(4,2)\n",
      "conv_1               f=16 quantized_bits(6,0,1,alpha=1.0) \n",
      "bn_conv_1            is normal keras bn layer\n",
      "conv_act_1           quantized_relu(4,2)\n",
      "conv_2               f=24 quantized_bits(6,0,1,alpha=1.0) \n",
      "bn_conv_2            is normal keras bn layer\n",
      "conv_act_2           quantized_relu(4,2)\n",
      "dense_0              u=42 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_dense_0           is normal keras bn layer\n",
      "dense_act_0          quantized_relu(8,2)\n",
      "dense_1              u=64 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_dense_1           is normal keras bn layer\n",
      "dense_act_1          quantized_relu(8,2)\n",
      "\n",
      "conv_0               f=16 quantized_bits(6,0,1,alpha=1.0) \n",
      "bn_conv_0            is normal keras bn layer\n",
      "conv_act_0           quantized_relu(4,2)\n",
      "conv_1               f=16 quantized_bits(6,0,1,alpha=1.0) \n",
      "bn_conv_1            is normal keras bn layer\n",
      "conv_act_1           quantized_relu(4,2)\n",
      "conv_2               f=24 quantized_bits(6,0,1,alpha=1.0) \n",
      "bn_conv_2            is normal keras bn layer\n",
      "conv_act_2           quantized_relu(4,2)\n",
      "dense_0              u=42 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_dense_0           is normal keras bn layer\n",
      "dense_act_0          quantized_relu(8,2)\n",
      "dense_1              u=64 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_dense_1           is normal keras bn layer\n",
      "dense_act_1          quantized_relu(8,2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aqmodel = autoqk.get_best_model()\n",
    "print_qmodel_summary(aqmodel)\n",
    "\n",
    "# Train for the full epochs\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3dfe746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "53/53 [==============================] - 4s 57ms/step - loss: 0.5604 - acc: 0.8708 - trial: 109680.0000 - score: 0.8853 - val_loss: 1.7038 - val_acc: 0.6353 - val_trial: 109680.0000 - val_score: 0.6459 - lr: 0.0030\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.2421 - acc: 0.9673 - trial: 109680.0000 - score: 0.9835 - val_loss: 1.0761 - val_acc: 0.6888 - val_trial: 109680.0000 - val_score: 0.7003 - lr: 0.0030\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.2017 - acc: 0.9753 - trial: 109680.0000 - score: 0.9916 - val_loss: 1.8768 - val_acc: 0.5097 - val_trial: 109680.0000 - val_score: 0.5182 - lr: 0.0030\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 3s 55ms/step - loss: 0.1837 - acc: 0.9777 - trial: 109680.0000 - score: 0.9941 - val_loss: 1.2711 - val_acc: 0.6157 - val_trial: 109680.0000 - val_score: 0.6259 - lr: 0.0030\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 3s 55ms/step - loss: 0.1675 - acc: 0.9803 - trial: 109680.0000 - score: 0.9966 - val_loss: 0.7763 - val_acc: 0.7877 - val_trial: 109680.0000 - val_score: 0.8008 - lr: 0.0030\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 3s 55ms/step - loss: 0.1558 - acc: 0.9820 - trial: 109680.0000 - score: 0.9984 - val_loss: 0.3946 - val_acc: 0.9035 - val_trial: 109680.0000 - val_score: 0.9186 - lr: 0.0030\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.1464 - acc: 0.9831 - trial: 109680.0000 - score: 0.9995 - val_loss: 0.2684 - val_acc: 0.9433 - val_trial: 109680.0000 - val_score: 0.9591 - lr: 0.0030\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.1370 - acc: 0.9847 - trial: 109680.0000 - score: 1.0011 - val_loss: 0.3407 - val_acc: 0.9173 - val_trial: 109680.0000 - val_score: 0.9326 - lr: 0.0030\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 3s 55ms/step - loss: 0.1333 - acc: 0.9846 - trial: 109680.0000 - score: 1.0010 - val_loss: 0.2729 - val_acc: 0.9457 - val_trial: 109680.0000 - val_score: 0.9614 - lr: 0.0030\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 3s 55ms/step - loss: 0.1290 - acc: 0.9848 - trial: 109680.0000 - score: 1.0013 - val_loss: 0.2002 - val_acc: 0.9627 - val_trial: 109680.0000 - val_score: 0.9787 - lr: 0.0030\n",
      "\n",
      " It took 0.49288323322931926 minutes to train!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = aqmodel.fit(train_data, epochs=n_epochs, validation_data=val_data, callbacks=callbacks, verbose=1)\n",
    "end = time.time()\n",
    "print('\\n It took {} minutes to train!\\n'.format((end - start) / 60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b0b2dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv_0 (QConv2D)            (None, 26, 26, 16)        144       \n",
      "                                                                 \n",
      " bn_conv_0 (BatchNormalizati  (None, 26, 26, 16)       64        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_act_0 (QActivation)    (None, 26, 26, 16)        0         \n",
      "                                                                 \n",
      " pool_0 (MaxPooling2D)       (None, 13, 13, 16)        0         \n",
      "                                                                 \n",
      " conv_1 (QConv2D)            (None, 11, 11, 16)        2304      \n",
      "                                                                 \n",
      " bn_conv_1 (BatchNormalizati  (None, 11, 11, 16)       64        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_act_1 (QActivation)    (None, 11, 11, 16)        0         \n",
      "                                                                 \n",
      " pool_1 (MaxPooling2D)       (None, 5, 5, 16)          0         \n",
      "                                                                 \n",
      " conv_2 (QConv2D)            (None, 3, 3, 24)          3456      \n",
      "                                                                 \n",
      " bn_conv_2 (BatchNormalizati  (None, 3, 3, 24)         96        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_act_2 (QActivation)    (None, 3, 3, 24)          0         \n",
      "                                                                 \n",
      " pool_2 (MaxPooling2D)       (None, 1, 1, 24)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 24)                0         \n",
      "                                                                 \n",
      " dense_0 (QDense)            (None, 42)                1008      \n",
      "                                                                 \n",
      " bn_dense_0 (BatchNormalizat  (None, 42)               168       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_act_0 (QActivation)   (None, 42)                0         \n",
      "                                                                 \n",
      " dense_1 (QDense)            (None, 64)                2688      \n",
      "                                                                 \n",
      " bn_dense_1 (BatchNormalizat  (None, 64)               256       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_act_1 (QActivation)   (None, 64)                0         \n",
      "                                                                 \n",
      " output_dense (Dense)        (None, 10)                650       \n",
      "                                                                 \n",
      " output_softmax (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,898\n",
      "Trainable params: 10,574\n",
      "Non-trainable params: 324\n",
      "_________________________________________________________________\n",
      "conv_0               f=16 quantized_bits(6,0,1,alpha=1.0) \n",
      "bn_conv_0            is normal keras bn layer\n",
      "conv_act_0           quantized_relu(4,2)\n",
      "conv_1               f=16 quantized_bits(6,0,1,alpha=1.0) \n",
      "bn_conv_1            is normal keras bn layer\n",
      "conv_act_1           quantized_relu(4,2)\n",
      "conv_2               f=24 quantized_bits(6,0,1,alpha=1.0) \n",
      "bn_conv_2            is normal keras bn layer\n",
      "conv_act_2           quantized_relu(4,2)\n",
      "dense_0              u=42 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_dense_0           is normal keras bn layer\n",
      "dense_act_0          quantized_relu(8,2)\n",
      "dense_1              u=64 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_dense_1           is normal keras bn layer\n",
      "dense_act_1          quantized_relu(8,2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This model has some remnants from the optimization procedure attached to it, so let's define a new one\n",
    "aqmodel.save_weights(\"autoqkeras_cnn_weights.h5\")\n",
    "\n",
    "layers = [l for l in aqmodel.layers]\n",
    "x = layers[0].output\n",
    "for i in range(1, len(layers)):\n",
    "    x = layers[i](x)\n",
    "\n",
    "new_model = Model(inputs=[layers[0].input], outputs=[x])\n",
    "LOSS = tf.keras.losses.CategoricalCrossentropy()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=3e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "\n",
    "new_model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "new_model.summary()\n",
    "new_model.load_weights(\"autoqkeras_cnn_weights.h5\")\n",
    "\n",
    "print_qmodel_summary(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04672a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to: models/new_model.h5\n",
      "Serving 'models/new_model.h5' at http://localhost:43287\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:43287\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7bd50757fca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the model \n",
    "new_model_path = os.path.join(model_dir, \"new_model\")\n",
    "save_model(new_model, new_model_path)\n",
    "\n",
    "view_model(new_model_path+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "865fdcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_0               f=16 quantized_bits(6,0,1,alpha=1.0) \n",
      "bn_conv_0            is normal keras bn layer\n",
      "conv_act_0           quantized_relu(4,2)\n",
      "conv_1               f=16 quantized_bits(6,0,1,alpha=1.0) \n",
      "bn_conv_1            is normal keras bn layer\n",
      "conv_act_1           quantized_relu(4,2)\n",
      "conv_2               f=24 quantized_bits(6,0,1,alpha=1.0) \n",
      "bn_conv_2            is normal keras bn layer\n",
      "conv_act_2           quantized_relu(4,2)\n",
      "dense_0              u=42 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_dense_0           is normal keras bn layer\n",
      "dense_act_0          quantized_relu(8,2)\n",
      "dense_1              u=64 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_dense_1           is normal keras bn layer\n",
      "dense_act_1          quantized_relu(8,2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_qmodel_summary(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2200f12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 28, 28, 1]], output shape: [None, 28, 28, 1]\n",
      "Layer name: conv_0, layer type: QConv2D, input shapes: [[None, 28, 28, 1]], output shape: [None, 26, 26, 16]\n",
      "Layer name: bn_conv_0, layer type: BatchNormalization, input shapes: [[None, 26, 26, 16]], output shape: [None, 26, 26, 16]\n",
      "Layer name: conv_act_0, layer type: Activation, input shapes: [[None, 26, 26, 16]], output shape: [None, 26, 26, 16]\n",
      "Layer name: pool_0, layer type: MaxPooling2D, input shapes: [[None, 26, 26, 16]], output shape: [None, 13, 13, 16]\n",
      "Layer name: conv_1, layer type: QConv2D, input shapes: [[None, 13, 13, 16]], output shape: [None, 11, 11, 16]\n",
      "Layer name: bn_conv_1, layer type: BatchNormalization, input shapes: [[None, 11, 11, 16]], output shape: [None, 11, 11, 16]\n",
      "Layer name: conv_act_1, layer type: Activation, input shapes: [[None, 11, 11, 16]], output shape: [None, 11, 11, 16]\n",
      "Layer name: pool_1, layer type: MaxPooling2D, input shapes: [[None, 11, 11, 16]], output shape: [None, 5, 5, 16]\n",
      "Layer name: conv_2, layer type: QConv2D, input shapes: [[None, 5, 5, 16]], output shape: [None, 3, 3, 24]\n",
      "Layer name: bn_conv_2, layer type: BatchNormalization, input shapes: [[None, 3, 3, 24]], output shape: [None, 3, 3, 24]\n",
      "Layer name: conv_act_2, layer type: Activation, input shapes: [[None, 3, 3, 24]], output shape: [None, 3, 3, 24]\n",
      "Layer name: pool_2, layer type: MaxPooling2D, input shapes: [[None, 3, 3, 24]], output shape: [None, 1, 1, 24]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 1, 1, 24]], output shape: [None, 24]\n",
      "Layer name: dense_0, layer type: QDense, input shapes: [[None, 24]], output shape: [None, 42]\n",
      "Layer name: bn_dense_0, layer type: BatchNormalization, input shapes: [[None, 42]], output shape: [None, 42]\n",
      "Layer name: dense_act_0, layer type: Activation, input shapes: [[None, 42]], output shape: [None, 42]\n",
      "Layer name: dense_1, layer type: QDense, input shapes: [[None, 42]], output shape: [None, 64]\n",
      "Layer name: bn_dense_1, layer type: BatchNormalization, input shapes: [[None, 64]], output shape: [None, 64]\n",
      "Layer name: dense_act_1, layer type: Activation, input shapes: [[None, 64]], output shape: [None, 64]\n",
      "Layer name: output_dense, layer type: Dense, input shapes: [[None, 64]], output shape: [None, 10]\n",
      "Layer name: output_softmax, layer type: Softmax, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Model\n",
      "  Precision:         ap_fixed<16,6>\n",
      "  ReuseFactor:       8\n",
      "  Strategy:          Latency\n",
      "  BramFactor:        1000000000\n",
      "  TraceOutput:       False\n",
      "LayerName\n",
      "  input_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  conv_0\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        fixed<6,1,TRN,WRAP,0>\n",
      "      bias:          auto\n",
      "  conv_0_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  bn_conv_0\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      scale:         auto\n",
      "      bias:          auto\n",
      "  conv_act_0\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        ufixed<4,2,RND_CONV,SAT,0>\n",
      "  pool_0\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  conv_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        fixed<6,1,TRN,WRAP,0>\n",
      "      bias:          auto\n",
      "  conv_1_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  bn_conv_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      scale:         auto\n",
      "      bias:          auto\n",
      "  conv_act_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        ufixed<4,2,RND_CONV,SAT,0>\n",
      "  pool_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  conv_2\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        fixed<6,1,TRN,WRAP,0>\n",
      "      bias:          auto\n",
      "  conv_2_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  bn_conv_2\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      scale:         auto\n",
      "      bias:          auto\n",
      "  conv_act_2\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        ufixed<4,2,RND_CONV,SAT,0>\n",
      "  pool_2\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  flatten\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  dense_0\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        fixed<2,1,TRN,WRAP,0>\n",
      "      bias:          auto\n",
      "  dense_0_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  bn_dense_0\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      scale:         auto\n",
      "      bias:          auto\n",
      "  dense_act_0\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        ufixed<8,2,RND_CONV,SAT,0>\n",
      "  dense_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        fixed<2,1,TRN,WRAP,0>\n",
      "      bias:          auto\n",
      "  dense_1_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  bn_dense_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      scale:         auto\n",
      "      bias:          auto\n",
      "  dense_act_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        ufixed<8,2,RND_CONV,SAT,0>\n",
      "  output_dense\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        auto\n",
      "      bias:          auto\n",
      "  output_dense_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  output_softmax\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "    Strategy:        Stable\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 28, 28, 1]], output shape: [None, 28, 28, 1]\n",
      "Layer name: conv_0, layer type: QConv2D, input shapes: [[None, 28, 28, 1]], output shape: [None, 26, 26, 16]\n",
      "Layer name: bn_conv_0, layer type: BatchNormalization, input shapes: [[None, 26, 26, 16]], output shape: [None, 26, 26, 16]\n",
      "Layer name: conv_act_0, layer type: Activation, input shapes: [[None, 26, 26, 16]], output shape: [None, 26, 26, 16]\n",
      "Layer name: pool_0, layer type: MaxPooling2D, input shapes: [[None, 26, 26, 16]], output shape: [None, 13, 13, 16]\n",
      "Layer name: conv_1, layer type: QConv2D, input shapes: [[None, 13, 13, 16]], output shape: [None, 11, 11, 16]\n",
      "Layer name: bn_conv_1, layer type: BatchNormalization, input shapes: [[None, 11, 11, 16]], output shape: [None, 11, 11, 16]\n",
      "Layer name: conv_act_1, layer type: Activation, input shapes: [[None, 11, 11, 16]], output shape: [None, 11, 11, 16]\n",
      "Layer name: pool_1, layer type: MaxPooling2D, input shapes: [[None, 11, 11, 16]], output shape: [None, 5, 5, 16]\n",
      "Layer name: conv_2, layer type: QConv2D, input shapes: [[None, 5, 5, 16]], output shape: [None, 3, 3, 24]\n",
      "Layer name: bn_conv_2, layer type: BatchNormalization, input shapes: [[None, 3, 3, 24]], output shape: [None, 3, 3, 24]\n",
      "Layer name: conv_act_2, layer type: Activation, input shapes: [[None, 3, 3, 24]], output shape: [None, 3, 3, 24]\n",
      "Layer name: pool_2, layer type: MaxPooling2D, input shapes: [[None, 3, 3, 24]], output shape: [None, 1, 1, 24]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 1, 1, 24]], output shape: [None, 24]\n",
      "Layer name: dense_0, layer type: QDense, input shapes: [[None, 24]], output shape: [None, 42]\n",
      "Layer name: bn_dense_0, layer type: BatchNormalization, input shapes: [[None, 42]], output shape: [None, 42]\n",
      "Layer name: dense_act_0, layer type: Activation, input shapes: [[None, 42]], output shape: [None, 42]\n",
      "Layer name: dense_1, layer type: QDense, input shapes: [[None, 42]], output shape: [None, 64]\n",
      "Layer name: bn_dense_1, layer type: BatchNormalization, input shapes: [[None, 64]], output shape: [None, 64]\n",
      "Layer name: dense_act_1, layer type: Activation, input shapes: [[None, 64]], output shape: [None, 64]\n",
      "Layer name: output_dense, layer type: Dense, input shapes: [[None, 64]], output shape: [None, 10]\n",
      "Layer name: output_softmax, layer type: Softmax, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "\n",
    "hls_config_aq = hls4ml.utils.config_from_keras_model(new_model, granularity='name')\n",
    "hls_config_aq['Model']['ReuseFactor'] = 8\n",
    "hls_config_aq['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "hls_config_aq['LayerName']['output_softmax']['Strategy'] = 'Stable'\n",
    "plotting.print_dict(hls_config_aq)\n",
    "\n",
    "cfg_aq = hls4ml.converters.create_config(backend='Vivado')\n",
    "cfg_aq['IOType'] = 'io_stream'  # Must set this if using CNNs!\n",
    "cfg_aq['HLSConfig'] = hls_config_aq\n",
    "cfg_aq['KerasModel'] = new_model\n",
    "cfg_aq['OutputDir'] = 'autoqkeras_cnn/'\n",
    "cfg_aq['XilinxPart'] = 'xczu5ev-sfvc784-1-i'\n",
    "\n",
    "hls_model_aq = hls4ml.converters.keras_to_hls(cfg_aq)\n",
    "hls_model_aq.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81eaf3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "Accuracy AutoQ Keras:  0.9615\n",
      "Accuracy AutoQ hls4ml: 0.9627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predict_aq = aqmodel.predict(x_test)\n",
    "y_predict_hls4ml_aq = hls_model_aq.predict(np.ascontiguousarray(x_test))\n",
    "\n",
    "\n",
    "accuracy_keras = float(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_predict_aq, axis=1)))\n",
    "accuracy_hls4ml = float(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_predict_hls4ml_aq, axis=1)))\n",
    "\n",
    "print(\"Accuracy AutoQ Keras:  {}\".format(accuracy_keras))\n",
    "print(\"Accuracy AutoQ hls4ml: {}\".format(accuracy_hls4ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66357107",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth = True\n",
    "if synth:\n",
    "    hls_model_aq.build(csim=False, synth=True, vsynth=True)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
