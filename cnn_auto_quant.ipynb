{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5ee6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 14:43:18.009317: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-06 14:43:18.081303: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-06 14:43:18.083448: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-04-06 14:43:18.083456: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-04-06 14:43:18.456287: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-04-06 14:43:18.456350: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-04-06 14:43:18.456355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Input, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.layers import Activation\n",
    "import time\n",
    "import os\n",
    "os.environ['XILINX_VITIS'] = '/tools/Xilinx/Vitis/2024.2'\n",
    "os.environ['PATH'] = '/tools/Xilinx/Vivado/2020.1/bin:' + os.environ['PATH']\n",
    "\n",
    "from model_utils import save_model\n",
    "from quant_utils import extract_quant_config, apply_quant_to_hls_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f706cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 14:43:19.347651: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2025-04-06 14:43:19.347691: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-04-06 14:43:19.347705: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu): /proc/driver/nvidia/version does not exist\n",
      "2025-04-06 14:43:19.347901: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to [0, 1]\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test  = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Reshape to add channel dimension (28x28x1)\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_test  = x_test.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test  = to_categorical(y_test, 10)\n",
    "\n",
    "# Split off a validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create tf.data.Dataset objects (optional but recommended for performance)\n",
    "batch_size = 1024\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(batch_size)\n",
    "val_data   = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size)\n",
    "test_data  = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "\n",
    "# Optional: set number of epochs\n",
    "n_epochs = 10\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04d348d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding convolutional block 0 with N=16 filters\n",
      "Adding convolutional block 1 with N=16 filters\n",
      "Adding convolutional block 2 with N=24 filters\n",
      "Adding dense block 0 with N=42 neurons\n",
      "Adding dense block 1 with N=64 neurons\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization\n",
    "\n",
    "filters_per_conv_layer = [16, 16, 24]\n",
    "neurons_per_dense_layer = [42, 64]\n",
    "\n",
    "x = x_in = Input(input_shape)\n",
    "\n",
    "for i, f in enumerate(filters_per_conv_layer):\n",
    "    print(('Adding convolutional block {} with N={} filters').format(i, f))\n",
    "    x = Conv2D(\n",
    "        int(f),\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=l1(0.0001),\n",
    "        use_bias=False,\n",
    "        name='conv_{}'.format(i),\n",
    "    )(x)\n",
    "    x = BatchNormalization(name='bn_conv_{}'.format(i))(x)\n",
    "    x = Activation('relu', name='conv_act_%i' % i)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='pool_{}'.format(i))(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "for i, n in enumerate(neurons_per_dense_layer):\n",
    "    print(('Adding dense block {} with N={} neurons').format(i, n))\n",
    "    x = Dense(n, kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001), name='dense_%i' % i, use_bias=False)(x)\n",
    "    x = BatchNormalization(name='bn_dense_{}'.format(i))(x)\n",
    "    x = Activation('relu', name='dense_act_%i' % i)(x)\n",
    "x = Dense(int(n_classes), name='output_dense')(x)\n",
    "x_out = Activation('softmax', name='output_softmax')(x)\n",
    "\n",
    "baseline_model = Model(inputs=[x_in], outputs=[x_out], name='keras_baseline')\n",
    "\n",
    "LOSS = tf.keras.losses.CategoricalCrossentropy()\n",
    "OPTIMIZER = tf.keras.optimizers.legacy.Adam(learning_rate=3e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "\n",
    "baseline_model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "# Copy the model to a new variable\n",
    "cloned_model = tf.keras.models.clone_model(baseline_model)\n",
    "cloned_model = tf.keras.models.clone_model(baseline_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa2d5223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m cloned_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mLOSS, optimizer\u001b[38;5;241m=\u001b[39mOPTIMIZER, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Train the cloned model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcloned_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Evaluate the cloned model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m cloned_model\u001b[38;5;241m.\u001b[39mevaluate(test_data, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compile the cloned model\n",
    "cloned_model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "# Train the cloned model\n",
    "cloned_model.fit(train_data, epochs=n_epochs, validation_data=val_data, verbose=2)\n",
    "\n",
    "\n",
    "# Evaluate the cloned model\n",
    "loss, accuracy = cloned_model.evaluate(test_data, verbose=2)\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {accuracy}\")\n",
    "# Save the model\n",
    "model_dir = \"models\"\n",
    "model_name = \"keras_baseline\"\n",
    "model_path = os.path.join(model_dir, model_name)\n",
    "save_model(cloned_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0fb744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netron_embed import view_model\n",
    "\n",
    "# View your model inline (any format: .onnx, .h5, .pb, etc.)\n",
    "view_model(model_path+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1073058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras import print_qstats\n",
    "\n",
    "# for automatic quantization\n",
    "import pprint\n",
    "from qkeras.autoqkeras import *\n",
    "from qkeras import *\n",
    "from qkeras.utils import model_quantize\n",
    "\n",
    "from qkeras.qtools import run_qtools\n",
    "from qkeras.qtools import settings as qtools_settings\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "from qkeras import quantized_bits\n",
    "from qkeras import QDense, QActivation\n",
    "\n",
    "q = run_qtools.QTools(\n",
    "    baseline_model,\n",
    "    process=\"horowitz\",\n",
    "    source_quantizers=[quantized_bits(16, 5, 1)],\n",
    "    is_inference=True,\n",
    "    weights_path=None,\n",
    "    keras_quantizer=\"fp16\",\n",
    "    keras_accumulator=\"fp16\",\n",
    "    for_reference=False,\n",
    ")\n",
    "q.qtools_stats_print()\n",
    "\n",
    "energy_dict = q.pe(\n",
    "    weights_on_memory=\"fixed\", activations_on_memory=\"fixed\", min_sram_size=8 * 16 * 1024 * 1024, rd_wr_on_io=False\n",
    ")\n",
    "\n",
    "# get stats of energy distribution in each layer\n",
    "energy_profile = q.extract_energy_profile(qtools_settings.cfg.include_energy, energy_dict)\n",
    "# extract sum of energy of each layer according to the rule specified in\n",
    "# qtools_settings.cfg.include_energy\n",
    "total_energy = q.extract_energy_sum(qtools_settings.cfg.include_energy, energy_dict)\n",
    "\n",
    "pprint.pprint(energy_profile)\n",
    "print()\n",
    "\n",
    "print(\"Total energy: {:.6f} uJ\".format(total_energy / 1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d665e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the quantizers we'll test in the bayesian optimization\n",
    "quantization_config = {\n",
    "    \"kernel\": {\n",
    "        \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n",
    "        \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "        \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n",
    "        \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n",
    "    },\n",
    "    \"bias\": {\n",
    "        \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n",
    "        \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "        \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n",
    "        \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n",
    "    },\n",
    "    \"activation\": {\n",
    "        \"quantized_relu(3,1)\": 3,\n",
    "        \"quantized_relu(4,2)\": 4,\n",
    "        \"quantized_relu(8,2)\": 8,\n",
    "        \"quantized_relu(8,4)\": 8,\n",
    "        \"quantized_relu(16,6)\": 16,\n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n",
    "        \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "        \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n",
    "        \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# These are the layer types we will quantize\n",
    "limit = {\n",
    "    \"conv\": [8, 8, 16],\n",
    "    \"dense\": [8, 8, 16],\n",
    "    \"act\": [16]\n",
    "}\n",
    "\n",
    "\n",
    "# Use this if you want to minimize the model bit size\n",
    "goal_bits = {\n",
    "    \"type\": \"bits\",\n",
    "    \"params\": {\n",
    "        \"delta_p\": 8.0,  # We tolerate up to a +8% accuracy change\n",
    "        \"delta_n\": 8.0,  # We tolerate down to a -8% accuracy change\n",
    "        \"rate\": 2.0,  # We want a x2 times smaller model\n",
    "        \"stress\": 1.0,  # Force the reference model size to be smaller by setting stress<1\n",
    "        \"input_bits\": 8,\n",
    "        \"output_bits\": 8,\n",
    "        \"ref_bits\": 8,\n",
    "        \"config\": {\"default\": [\"parameters\", \"activations\"]},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Use this if you want to minimize the model energy consumption\n",
    "goal_energy = {\n",
    "    \"type\": \"energy\",\n",
    "    \"params\": {\n",
    "        \"delta_p\": 8.0,\n",
    "        \"delta_n\": 8.0,\n",
    "        \"rate\": 2.0,\n",
    "        \"stress\": 1.0,\n",
    "        \"process\": \"horowitz\",\n",
    "        \"parameters_on_memory\": [\"sram\", \"sram\"],\n",
    "        \"activations_on_memory\": [\"sram\", \"sram\"],\n",
    "        \"rd_wr_on_io\": [False, False],\n",
    "        \"min_sram_size\": [0, 0],\n",
    "        \"source_quantizers\": [\"fp32\"],\n",
    "        \"reference_internal\": \"int8\",\n",
    "        \"reference_accumulator\": \"int32\",\n",
    "    },\n",
    "}\n",
    "\n",
    "run_config = {\n",
    "    \"goal\": goal_energy,\n",
    "    \"quantization_config\": quantization_config,\n",
    "    \"learning_rate_optimizer\": False,\n",
    "    \"transfer_weights\": False,  # Randomely initialize weights\n",
    "    \"mode\": \"bayesian\",  # This can be bayesian,random,hyperband\n",
    "    \"seed\": 42,\n",
    "    \"limit\": limit,\n",
    "    \"tune_filters\": \"layer\",\n",
    "    \"tune_filters_exceptions\": \"^output\",\n",
    "    \"distribution_strategy\": None,\n",
    "    \"max_trials\": 5,  # Let's just do 5 trials for this demonstrator, ideally you should do as many as possible\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f86536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras.autoqkeras import AutoQKeras\n",
    "autoqk = AutoQKeras(\n",
    "    model=baseline_model,\n",
    "    output_dir=\"autoqk_results\",\n",
    "    **run_config\n",
    ")\n",
    "\n",
    "space = autoqk.tuner.oracle.get_space()\n",
    "print(\"\\n🔍 Registered hyperparameters:\")\n",
    "for hp in space.space:\n",
    "    print(f\"• {hp.name}: {hp.values}\")\n",
    "\n",
    "\n",
    "autoqk.fit(\n",
    "    x=train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=15  # Or however many you want for each trial\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d5180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqmodel = autoqk.get_best_model()\n",
    "print_qmodel_summary(aqmodel)\n",
    "\n",
    "# Train for the full epochs\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
    "]\n",
    "\n",
    "start = time.time()\n",
    "history = aqmodel.fit(train_data, epochs=n_epochs, validation_data=val_data, callbacks=callbacks, verbose=1)\n",
    "end = time.time()\n",
    "print('\\n It took {} minutes to train!\\n'.format((end - start) / 60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f912ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_model(\"autoqkeras_cnn_weights.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0b2dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model has some remnants from the optimization procedure attached to it, so let's define a new one\n",
    "aqmodel.save_weights(\"autoqkeras_cnn_weights.h5\")\n",
    "\n",
    "layers = [l for l in aqmodel.layers]\n",
    "x = layers[0].output\n",
    "for i in range(1, len(layers)):\n",
    "    x = layers[i](x)\n",
    "\n",
    "new_model = Model(inputs=[layers[0].input], outputs=[x])\n",
    "LOSS = tf.keras.losses.CategoricalCrossentropy()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=3e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "\n",
    "new_model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "new_model.summary()\n",
    "new_model.load_weights(\"autoqkeras_cnn_weights.h5\")\n",
    "print_qmodel_summary(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "\n",
    "hls_config_aq = hls4ml.utils.config_from_keras_model(new_model, granularity='name')\n",
    "hls_config_aq['Model']['ReuseFactor'] = 2\n",
    "hls_config_aq['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "hls_config_aq['LayerName']['output_softmax']['Strategy'] = 'Stable'\n",
    "plotting.print_dict(hls_config_aq)\n",
    "\n",
    "cfg_aq = hls4ml.converters.create_config(backend='Vivado')\n",
    "cfg_aq['IOType'] = 'io_stream'  # Must set this if using CNNs!\n",
    "cfg_aq['HLSConfig'] = hls_config_aq\n",
    "cfg_aq['KerasModel'] = new_model\n",
    "cfg_aq['OutputDir'] = 'autoqkeras_cnn/'\n",
    "cfg_aq['XilinxPart'] = 'xczu5ev-sfvc784-1-i'\n",
    "\n",
    "hls_model_aq = hls4ml.converters.keras_to_hls(cfg_aq)\n",
    "hls_model_aq.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eaf3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predict_aq = aqmodel.predict(x_test)\n",
    "y_predict_hls4ml_aq = hls_model_aq.predict(np.ascontiguousarray(x_test))\n",
    "\n",
    "\n",
    "accuracy_keras = float(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_predict_aq, axis=1)))\n",
    "accuracy_hls4ml = float(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_predict_hls4ml_aq, axis=1)))\n",
    "\n",
    "print(\"Accuracy AutoQ Keras:  {}\".format(accuracy_keras))\n",
    "print(\"Accuracy AutoQ hls4ml: {}\".format(accuracy_hls4ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66357107",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth = True\n",
    "if synth:\n",
    "    hls_model_aq.build(csim=False, synth=True, vsynth=True)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
