{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5ee6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 22:19:04.089212: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-06 22:19:04.156421: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-06 22:19:04.158927: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-04-06 22:19:04.158939: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-04-06 22:19:04.507056: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-04-06 22:19:04.507114: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-04-06 22:19:04.507119: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Input, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.layers import Activation\n",
    "import time\n",
    "import os\n",
    "os.environ['XILINX_VITIS'] = '/tools/Xilinx/Vitis/2024.2'\n",
    "os.environ['PATH'] = '/tools/Xilinx/Vivado/2020.1/bin:' + os.environ['PATH']\n",
    "\n",
    "from model_utils import save_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f706cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 22:19:16.442941: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2025-04-06 22:19:16.450255: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-04-06 22:19:16.450283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ubuntu): /proc/driver/nvidia/version does not exist\n",
      "2025-04-06 22:19:16.484468: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to [0, 1]\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test  = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Reshape to add channel dimension (28x28x1)\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_test  = x_test.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test  = to_categorical(y_test, 10)\n",
    "\n",
    "# Split off a validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create tf.data.Dataset objects (optional but recommended for performance)\n",
    "batch_size = 1024\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(batch_size)\n",
    "val_data   = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size)\n",
    "test_data  = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "\n",
    "# Optional: set number of epochs\n",
    "n_epochs = 10\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04d348d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding convolutional block 0 with N=16 filters\n",
      "Adding convolutional block 1 with N=16 filters\n",
      "Adding convolutional block 2 with N=24 filters\n",
      "Adding dense block 0 with N=42 neurons\n",
      "Adding dense block 1 with N=64 neurons\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization\n",
    "\n",
    "filters_per_conv_layer = [16, 16, 24]\n",
    "neurons_per_dense_layer = [42, 64]\n",
    "\n",
    "x = x_in = Input(input_shape)\n",
    "\n",
    "for i, f in enumerate(filters_per_conv_layer):\n",
    "    print(('Adding convolutional block {} with N={} filters').format(i, f))\n",
    "    x = Conv2D(\n",
    "        int(f),\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=l1(0.0001),\n",
    "        use_bias=False,\n",
    "        name='conv_{}'.format(i),\n",
    "    )(x)\n",
    "    x = BatchNormalization(name='bn_conv_{}'.format(i))(x)\n",
    "    x = Activation('relu', name='conv_act_%i' % i)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='pool_{}'.format(i))(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "for i, n in enumerate(neurons_per_dense_layer):\n",
    "    print(('Adding dense block {} with N={} neurons').format(i, n))\n",
    "    x = Dense(n, kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001), name='dense_%i' % i, use_bias=False)(x)\n",
    "    x = BatchNormalization(name='bn_dense_{}'.format(i))(x)\n",
    "    x = Activation('relu', name='dense_act_%i' % i)(x)\n",
    "x = Dense(int(n_classes), name='output_dense')(x)\n",
    "x_out = Activation('softmax', name='output_softmax')(x)\n",
    "\n",
    "baseline_model = Model(inputs=[x_in], outputs=[x_out], name='keras_baseline')\n",
    "\n",
    "LOSS = tf.keras.losses.CategoricalCrossentropy()\n",
    "OPTIMIZER = tf.keras.optimizers.legacy.Adam(learning_rate=3e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "\n",
    "baseline_model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "# Copy the model to a new variable\n",
    "cloned_model = tf.keras.models.clone_model(baseline_model)\n",
    "cloned_model = tf.keras.models.clone_model(baseline_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa2d5223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "53/53 - 5s - loss: 0.8224 - accuracy: 0.7873 - val_loss: 1.1067 - val_accuracy: 0.8960 - 5s/epoch - 101ms/step\n",
      "Epoch 2/10\n",
      "53/53 - 2s - loss: 0.2524 - accuracy: 0.9546 - val_loss: 0.9763 - val_accuracy: 0.7975 - 2s/epoch - 33ms/step\n",
      "Epoch 3/10\n",
      "53/53 - 2s - loss: 0.1955 - accuracy: 0.9706 - val_loss: 0.9489 - val_accuracy: 0.7593 - 2s/epoch - 34ms/step\n",
      "Epoch 4/10\n",
      "53/53 - 2s - loss: 0.1667 - accuracy: 0.9779 - val_loss: 0.8226 - val_accuracy: 0.7808 - 2s/epoch - 30ms/step\n",
      "Epoch 5/10\n",
      "53/53 - 2s - loss: 0.1502 - accuracy: 0.9812 - val_loss: 0.5244 - val_accuracy: 0.8728 - 2s/epoch - 29ms/step\n",
      "Epoch 6/10\n",
      "53/53 - 2s - loss: 0.1347 - accuracy: 0.9846 - val_loss: 0.3153 - val_accuracy: 0.9267 - 2s/epoch - 29ms/step\n",
      "Epoch 7/10\n",
      "53/53 - 2s - loss: 0.1261 - accuracy: 0.9866 - val_loss: 0.2171 - val_accuracy: 0.9568 - 2s/epoch - 29ms/step\n",
      "Epoch 8/10\n",
      "53/53 - 2s - loss: 0.1171 - accuracy: 0.9876 - val_loss: 0.1884 - val_accuracy: 0.9658 - 2s/epoch - 28ms/step\n",
      "Epoch 9/10\n",
      "53/53 - 1s - loss: 0.1101 - accuracy: 0.9887 - val_loss: 0.1817 - val_accuracy: 0.9645 - 1s/epoch - 28ms/step\n",
      "Epoch 10/10\n",
      "53/53 - 1s - loss: 0.1034 - accuracy: 0.9900 - val_loss: 0.2090 - val_accuracy: 0.9540 - 1s/epoch - 28ms/step\n",
      "10/10 - 0s - loss: 0.1982 - accuracy: 0.9597 - 85ms/epoch - 9ms/step\n",
      "Test loss: 0.19822418689727783\n",
      "Test accuracy: 0.9596999883651733\n",
      "✅ Model saved to: models/keras_baseline.h5\n"
     ]
    }
   ],
   "source": [
    "# Compile the cloned model\n",
    "cloned_model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "# Train the cloned model\n",
    "cloned_model.fit(train_data, epochs=n_epochs, validation_data=val_data, verbose=2)\n",
    "\n",
    "\n",
    "# Evaluate the cloned model\n",
    "loss, accuracy = cloned_model.evaluate(test_data, verbose=2)\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {accuracy}\")\n",
    "# Save the model\n",
    "model_dir = \"models\"\n",
    "model_name = \"keras_baseline\"\n",
    "model_path = os.path.join(model_dir, model_name)\n",
    "save_model(cloned_model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb0fb744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'models/keras_baseline.h5' at http://localhost:33767\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:33767\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f02178569e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from netron_embed import view_model\n",
    "\n",
    "# View your model inline (any format: .onnx, .h5, .pb, etc.)\n",
    "view_model(model_path+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1073058e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/theodoros/miniconda3/envs/myenv/lib/python3.10/site-packages/qkeras/qtools/qgraph.py:189: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "{\n",
      "    \"source_quantizers\": [\n",
      "        {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 16,\n",
      "            \"int_bits\": 6,\n",
      "            \"is_signed\": true\n",
      "        }\n",
      "    ],\n",
      "    \"conv_0\": {\n",
      "        \"layer_type\": \"Conv2D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 16,\n",
      "                \"int_bits\": 6,\n",
      "                \"is_signed\": true\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                3,\n",
      "                1,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                26,\n",
      "                26,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 97344\n",
      "    },\n",
      "    \"bn_conv_0\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                26,\n",
      "                26,\n",
      "                16\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"conv_act_0\": {\n",
      "        \"layer_type\": \"Activation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                26,\n",
      "                26,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 10816\n",
      "    },\n",
      "    \"pool_0\": {\n",
      "        \"layer_type\": \"MaxPooling2D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                13,\n",
      "                13,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 10816\n",
      "    },\n",
      "    \"conv_1\": {\n",
      "        \"layer_type\": \"Conv2D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                3,\n",
      "                16,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                11,\n",
      "                11,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 278784\n",
      "    },\n",
      "    \"bn_conv_1\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                11,\n",
      "                11,\n",
      "                16\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"conv_act_1\": {\n",
      "        \"layer_type\": \"Activation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                11,\n",
      "                11,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 1936\n",
      "    },\n",
      "    \"pool_1\": {\n",
      "        \"layer_type\": \"MaxPooling2D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                5,\n",
      "                5,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 1936\n",
      "    },\n",
      "    \"conv_2\": {\n",
      "        \"layer_type\": \"Conv2D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                3,\n",
      "                16,\n",
      "                24\n",
      "            ]\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                3,\n",
      "                3,\n",
      "                24\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 31104\n",
      "    },\n",
      "    \"bn_conv_2\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                3,\n",
      "                3,\n",
      "                24\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"conv_act_2\": {\n",
      "        \"layer_type\": \"Activation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                3,\n",
      "                3,\n",
      "                24\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 216\n",
      "    },\n",
      "    \"pool_2\": {\n",
      "        \"layer_type\": \"MaxPooling2D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                1,\n",
      "                1,\n",
      "                24\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 216\n",
      "    },\n",
      "    \"flatten\": {\n",
      "        \"layer_type\": \"Flatten\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                24\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 24\n",
      "    },\n",
      "    \"dense_0\": {\n",
      "        \"layer_type\": \"Dense\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                24,\n",
      "                42\n",
      "            ]\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                42\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 1008\n",
      "    },\n",
      "    \"bn_dense_0\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                42\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"dense_act_0\": {\n",
      "        \"layer_type\": \"Activation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                42\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 42\n",
      "    },\n",
      "    \"dense_1\": {\n",
      "        \"layer_type\": \"Dense\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                42,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 2688\n",
      "    },\n",
      "    \"bn_dense_1\": {\n",
      "        \"layer_type\": \"BatchNormalization\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"gamma_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"beta_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"mean_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"variance_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16\n",
      "        },\n",
      "        \"internal_divide_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"internal_accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                64\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"dense_act_1\": {\n",
      "        \"layer_type\": \"Activation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                64\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 64\n",
      "    },\n",
      "    \"output_dense\": {\n",
      "        \"layer_type\": \"Dense\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                64,\n",
      "                10\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": 10\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                10\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 640\n",
      "    },\n",
      "    \"output_softmax\": {\n",
      "        \"layer_type\": \"Activation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                10\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 10\n",
      "    }\n",
      "}\n",
      "{'bn_conv_0': {'energy': {'inputs': 0.0,\n",
      "                          'op_cost': 23795.2,\n",
      "                          'outputs': 0.0,\n",
      "                          'parameters': 0.0},\n",
      "               'total': 0.0},\n",
      " 'bn_conv_1': {'energy': {'inputs': 0.0,\n",
      "                          'op_cost': 4259.2,\n",
      "                          'outputs': 0.0,\n",
      "                          'parameters': 0.0},\n",
      "               'total': 0.0},\n",
      " 'bn_conv_2': {'energy': {'inputs': 0.0,\n",
      "                          'op_cost': 475.2,\n",
      "                          'outputs': 0.0,\n",
      "                          'parameters': 0.0},\n",
      "               'total': 0.0},\n",
      " 'bn_dense_0': {'energy': {'inputs': 0.0,\n",
      "                           'op_cost': 92.4,\n",
      "                           'outputs': 0.0,\n",
      "                           'parameters': 0.0},\n",
      "                'total': 0.0},\n",
      " 'bn_dense_1': {'energy': {'inputs': 0.0,\n",
      "                           'op_cost': 140.8,\n",
      "                           'outputs': 0.0,\n",
      "                           'parameters': 0.0},\n",
      "                'total': 0.0},\n",
      " 'conv_0': {'energy': {'inputs': 745.54,\n",
      "                       'op_cost': 146016.0,\n",
      "                       'outputs': 0.0,\n",
      "                       'parameters': 0.0},\n",
      "            'total': 146761.54},\n",
      " 'conv_1': {'energy': {'inputs': 0.0,\n",
      "                       'op_cost': 418176.0,\n",
      "                       'outputs': 0.0,\n",
      "                       'parameters': 0.0},\n",
      "            'total': 418176.0},\n",
      " 'conv_2': {'energy': {'inputs': 0.0,\n",
      "                       'op_cost': 46656.0,\n",
      "                       'outputs': 0.0,\n",
      "                       'parameters': 0.0},\n",
      "            'total': 46656.0},\n",
      " 'conv_act_0': {'energy': {'inputs': 0.0,\n",
      "                           'op_cost': 0.0,\n",
      "                           'outputs': 0.0,\n",
      "                           'parameters': 0.0},\n",
      "                'total': 0.0},\n",
      " 'conv_act_1': {'energy': {'inputs': 0.0,\n",
      "                           'op_cost': 0.0,\n",
      "                           'outputs': 0.0,\n",
      "                           'parameters': 0.0},\n",
      "                'total': 0.0},\n",
      " 'conv_act_2': {'energy': {'inputs': 0.0,\n",
      "                           'op_cost': 0.0,\n",
      "                           'outputs': 0.0,\n",
      "                           'parameters': 0.0},\n",
      "                'total': 0.0},\n",
      " 'dense_0': {'energy': {'inputs': 0.0,\n",
      "                        'op_cost': 1512.0,\n",
      "                        'outputs': 0.0,\n",
      "                        'parameters': 0.0},\n",
      "             'total': 1512.0},\n",
      " 'dense_1': {'energy': {'inputs': 0.0,\n",
      "                        'op_cost': 4032.0,\n",
      "                        'outputs': 0.0,\n",
      "                        'parameters': 0.0},\n",
      "             'total': 4032.0},\n",
      " 'dense_act_0': {'energy': {'inputs': 0.0,\n",
      "                            'op_cost': 0.0,\n",
      "                            'outputs': 0.0,\n",
      "                            'parameters': 0.0},\n",
      "                 'total': 0.0},\n",
      " 'dense_act_1': {'energy': {'inputs': 0.0,\n",
      "                            'op_cost': 0.0,\n",
      "                            'outputs': 0.0,\n",
      "                            'parameters': 0.0},\n",
      "                 'total': 0.0},\n",
      " 'flatten': {'energy': {'inputs': 0.0,\n",
      "                        'op_cost': 0.0,\n",
      "                        'outputs': 0.0,\n",
      "                        'parameters': 0.0},\n",
      "             'total': 0.0},\n",
      " 'output_dense': {'energy': {'inputs': 0.0,\n",
      "                             'op_cost': 960.0,\n",
      "                             'outputs': 0.0,\n",
      "                             'parameters': 0.0},\n",
      "                  'total': 960.0},\n",
      " 'output_softmax': {'energy': {'inputs': 0.0,\n",
      "                               'op_cost': 0.0,\n",
      "                               'outputs': 11.41,\n",
      "                               'parameters': 0.0},\n",
      "                    'total': 11.41},\n",
      " 'pool_0': {'energy': {'inputs': 0.0,\n",
      "                       'op_cost': 0.0,\n",
      "                       'outputs': 0.0,\n",
      "                       'parameters': 0.0},\n",
      "            'total': 0.0},\n",
      " 'pool_1': {'energy': {'inputs': 0.0,\n",
      "                       'op_cost': 0.0,\n",
      "                       'outputs': 0.0,\n",
      "                       'parameters': 0.0},\n",
      "            'total': 0.0},\n",
      " 'pool_2': {'energy': {'inputs': 0.0,\n",
      "                       'op_cost': 0.0,\n",
      "                       'outputs': 0.0,\n",
      "                       'parameters': 0.0},\n",
      "            'total': 0.0}}\n",
      "\n",
      "Total energy: 0.618108 uJ\n"
     ]
    }
   ],
   "source": [
    "from qkeras import print_qstats\n",
    "\n",
    "# for automatic quantization\n",
    "import pprint\n",
    "from qkeras.autoqkeras import *\n",
    "from qkeras import *\n",
    "from qkeras.utils import model_quantize\n",
    "\n",
    "from qkeras.qtools import run_qtools\n",
    "from qkeras.qtools import settings as qtools_settings\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "from qkeras import quantized_bits\n",
    "from qkeras import QDense, QActivation\n",
    "\n",
    "q = run_qtools.QTools(\n",
    "    baseline_model,\n",
    "    process=\"horowitz\",\n",
    "    source_quantizers=[quantized_bits(16, 5, 1)],\n",
    "    is_inference=True,\n",
    "    weights_path=None,\n",
    "    keras_quantizer=\"fp16\",\n",
    "    keras_accumulator=\"fp16\",\n",
    "    for_reference=False,\n",
    ")\n",
    "q.qtools_stats_print()\n",
    "\n",
    "energy_dict = q.pe(\n",
    "    weights_on_memory=\"fixed\", activations_on_memory=\"fixed\", min_sram_size=8 * 16 * 1024 * 1024, rd_wr_on_io=False\n",
    ")\n",
    "\n",
    "# get stats of energy distribution in each layer\n",
    "energy_profile = q.extract_energy_profile(qtools_settings.cfg.include_energy, energy_dict)\n",
    "# extract sum of energy of each layer according to the rule specified in\n",
    "# qtools_settings.cfg.include_energy\n",
    "total_energy = q.extract_energy_sum(qtools_settings.cfg.include_energy, energy_dict)\n",
    "\n",
    "pprint.pprint(energy_profile)\n",
    "print()\n",
    "\n",
    "print(\"Total energy: {:.6f} uJ\".format(total_energy / 1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d665e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the quantizers we'll test in the bayesian optimization\n",
    "quantization_config = {\n",
    "    \"kernel\": {\n",
    "        \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n",
    "        \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "        \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n",
    "        \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n",
    "    },\n",
    "    \"bias\": {\n",
    "        \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n",
    "        \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "        \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n",
    "        \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n",
    "    },\n",
    "    \"activation\": {\n",
    "        \"quantized_relu(3,1)\": 3,\n",
    "        \"quantized_relu(4,2)\": 4,\n",
    "        \"quantized_relu(8,2)\": 8,\n",
    "        \"quantized_relu(8,4)\": 8,\n",
    "        \"quantized_relu(16,6)\": 16,\n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"quantized_bits(2,0,1,alpha=1.0)\": 2,\n",
    "        \"quantized_bits(4,0,1,alpha=1.0)\": 4,\n",
    "        \"quantized_bits(6,0,1,alpha=1.0)\": 6,\n",
    "        \"quantized_bits(8,0,1,alpha=1.0)\": 8,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# These are the layer types we will quantize\n",
    "limit = {\n",
    "    \"conv\": [8, 8, 16],\n",
    "    \"dense\": [8, 8, 16],\n",
    "    \"act\": [16]\n",
    "}\n",
    "\n",
    "\n",
    "# Use this if you want to minimize the model bit size\n",
    "goal_bits = {\n",
    "    \"type\": \"bits\",\n",
    "    \"params\": {\n",
    "        \"delta_p\": 8.0,  # We tolerate up to a +8% accuracy change\n",
    "        \"delta_n\": 8.0,  # We tolerate down to a -8% accuracy change\n",
    "        \"rate\": 2.0,  # We want a x2 times smaller model\n",
    "        \"stress\": 1.0,  # Force the reference model size to be smaller by setting stress<1\n",
    "        \"input_bits\": 8,\n",
    "        \"output_bits\": 8,\n",
    "        \"ref_bits\": 8,\n",
    "        \"config\": {\"default\": [\"parameters\", \"activations\"]},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Use this if you want to minimize the model energy consumption\n",
    "goal_energy = {\n",
    "    \"type\": \"energy\",\n",
    "    \"params\": {\n",
    "        \"delta_p\": 8.0,\n",
    "        \"delta_n\": 8.0,\n",
    "        \"rate\": 2.0,\n",
    "        \"stress\": 1.0,\n",
    "        \"process\": \"horowitz\",\n",
    "        \"parameters_on_memory\": [\"sram\", \"sram\"],\n",
    "        \"activations_on_memory\": [\"sram\", \"sram\"],\n",
    "        \"rd_wr_on_io\": [False, False],\n",
    "        \"min_sram_size\": [0, 0],\n",
    "        \"source_quantizers\": [\"fp32\"],\n",
    "        \"reference_internal\": \"int8\",\n",
    "        \"reference_accumulator\": \"int32\",\n",
    "    },\n",
    "}\n",
    "\n",
    "run_config = {\n",
    "    \"goal\": goal_energy,\n",
    "    \"quantization_config\": quantization_config,\n",
    "    \"learning_rate_optimizer\": False,\n",
    "    \"transfer_weights\": False,  # Randomely initialize weights\n",
    "    \"mode\": \"bayesian\",  # This can be bayesian,random,hyperband\n",
    "    \"seed\": 42,\n",
    "    \"limit\": limit,\n",
    "    \"tune_filters\": \"layer\",\n",
    "    \"tune_filters_exceptions\": \"^output\",\n",
    "    \"distribution_strategy\": None,\n",
    "    \"max_trials\": 5,  # Let's just do 5 trials for this demonstrator, ideally you should do as many as possible\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f86536d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 51s]\n",
      "val_score: 0.9569714069366455\n",
      "\n",
      "Best val_score So Far: 0.9569714069366455\n",
      "Total elapsed time: 00h 04m 35s\n"
     ]
    }
   ],
   "source": [
    "from qkeras.autoqkeras import AutoQKeras\n",
    "autoqk = AutoQKeras(\n",
    "    model=baseline_model,\n",
    "    output_dir=\"autoqk_results\",\n",
    "    **run_config\n",
    ")\n",
    "\n",
    "space = autoqk.tuner.oracle.get_space()\n",
    "print(\"\\n🔍 Registered hyperparameters:\")\n",
    "for hp in space.space:\n",
    "    print(f\"• {hp.name}: {hp.values}\")\n",
    "\n",
    "\n",
    "autoqk.fit(\n",
    "    x=train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=15  # Or however many you want for each trial\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d5180d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.003000000026077032\n",
      "Model: \"keras_baseline\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv_0 (QConv2D)            (None, 26, 26, 12)        108       \n",
      "                                                                 \n",
      " bn_conv_0 (BatchNormalizati  (None, 26, 26, 12)       48        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_act_0 (QActivation)    (None, 26, 26, 12)        0         \n",
      "                                                                 \n",
      " pool_0 (MaxPooling2D)       (None, 13, 13, 12)        0         \n",
      "                                                                 \n",
      " conv_1 (QConv2D)            (None, 11, 11, 8)         864       \n",
      "                                                                 \n",
      " bn_conv_1 (BatchNormalizati  (None, 11, 11, 8)        32        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_act_1 (QActivation)    (None, 11, 11, 8)         0         \n",
      "                                                                 \n",
      " pool_1 (MaxPooling2D)       (None, 5, 5, 8)           0         \n",
      "                                                                 \n",
      " conv_2 (QConv2D)            (None, 3, 3, 24)          1728      \n",
      "                                                                 \n",
      " bn_conv_2 (BatchNormalizati  (None, 3, 3, 24)         96        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_act_2 (QActivation)    (None, 3, 3, 24)          0         \n",
      "                                                                 \n",
      " pool_2 (MaxPooling2D)       (None, 1, 1, 24)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 24)                0         \n",
      "                                                                 \n",
      " dense_0 (QDense)            (None, 63)                1512      \n",
      "                                                                 \n",
      " bn_dense_0 (BatchNormalizat  (None, 63)               252       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_act_0 (QActivation)   (None, 63)                0         \n",
      "                                                                 \n",
      " dense_1 (QDense)            (None, 96)                6048      \n",
      "                                                                 \n",
      " bn_dense_1 (BatchNormalizat  (None, 96)               384       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_act_1 (QActivation)   (None, 96)                0         \n",
      "                                                                 \n",
      " output_dense (Dense)        (None, 10)                970       \n",
      "                                                                 \n",
      " output_softmax (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,042\n",
      "Trainable params: 11,636\n",
      "Non-trainable params: 406\n",
      "_________________________________________________________________\n",
      "stats: delta_p=0.08 delta_n=0.08 rate=2.0 trial_size=369570 reference_size=309427\n",
      "       delta=-2.05%\n",
      "Total Cost Reduction:\n",
      "       369570 vs 309427 (19.44%)\n",
      "conv_0               f=12 quantized_bits(8,0,1,alpha=1.0) \n",
      "bn_conv_0            is normal keras bn layer\n",
      "conv_act_0           quantized_relu(8,2)\n",
      "conv_1               f=8 quantized_bits(8,0,1,alpha=1.0) \n",
      "bn_conv_1            is normal keras bn layer\n",
      "conv_act_1           quantized_relu(8,2)\n",
      "conv_2               f=24 quantized_bits(8,0,1,alpha=1.0) \n",
      "bn_conv_2            is normal keras bn layer\n",
      "conv_act_2           quantized_relu(8,2)\n",
      "dense_0              u=63 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_dense_0           is normal keras bn layer\n",
      "dense_act_0          quantized_relu(3,1)\n",
      "dense_1              u=96 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_dense_1           is normal keras bn layer\n",
      "dense_act_1          quantized_relu(3,1)\n",
      "\n",
      "conv_0               f=12 quantized_bits(8,0,1,alpha=1.0) \n",
      "bn_conv_0            is normal keras bn layer\n",
      "conv_act_0           quantized_relu(8,2)\n",
      "conv_1               f=8 quantized_bits(8,0,1,alpha=1.0) \n",
      "bn_conv_1            is normal keras bn layer\n",
      "conv_act_1           quantized_relu(8,2)\n",
      "conv_2               f=24 quantized_bits(8,0,1,alpha=1.0) \n",
      "bn_conv_2            is normal keras bn layer\n",
      "conv_act_2           quantized_relu(8,2)\n",
      "dense_0              u=63 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_dense_0           is normal keras bn layer\n",
      "dense_act_0          quantized_relu(3,1)\n",
      "dense_1              u=96 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_dense_1           is normal keras bn layer\n",
      "dense_act_1          quantized_relu(3,1)\n",
      "\n",
      "Epoch 1/10\n",
      "53/53 [==============================] - 4s 68ms/step - loss: 0.6484 - acc: 0.8740 - trial: 369570.0000 - score: 0.8561 - val_loss: 1.6132 - val_acc: 0.6620 - val_trial: 369570.0000 - val_score: 0.6484 - lr: 0.0030\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 3s 63ms/step - loss: 0.3137 - acc: 0.9668 - trial: 369570.0000 - score: 0.9470 - val_loss: 0.4411 - val_acc: 0.9220 - val_trial: 369570.0000 - val_score: 0.9031 - lr: 0.0030\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 4s 70ms/step - loss: 0.2538 - acc: 0.9746 - trial: 369570.0000 - score: 0.9546 - val_loss: 0.5256 - val_acc: 0.8778 - val_trial: 369570.0000 - val_score: 0.8598 - lr: 0.0030\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 3s 65ms/step - loss: 0.2162 - acc: 0.9765 - trial: 369570.0000 - score: 0.9565 - val_loss: 0.4755 - val_acc: 0.8903 - val_trial: 369570.0000 - val_score: 0.8721 - lr: 0.0030\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 3s 65ms/step - loss: 0.1941 - acc: 0.9787 - trial: 369570.0000 - score: 0.9587 - val_loss: 0.3593 - val_acc: 0.9223 - val_trial: 369570.0000 - val_score: 0.9034 - lr: 0.0030\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 3s 62ms/step - loss: 0.1787 - acc: 0.9791 - trial: 369570.0000 - score: 0.9591 - val_loss: 0.2475 - val_acc: 0.9595 - val_trial: 369570.0000 - val_score: 0.9398 - lr: 0.0030\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 3s 61ms/step - loss: 0.1649 - acc: 0.9816 - trial: 369570.0000 - score: 0.9615 - val_loss: 0.2345 - val_acc: 0.9615 - val_trial: 369570.0000 - val_score: 0.9418 - lr: 0.0030\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 3s 63ms/step - loss: 0.1566 - acc: 0.9819 - trial: 369570.0000 - score: 0.9618 - val_loss: 0.2722 - val_acc: 0.9472 - val_trial: 369570.0000 - val_score: 0.9277 - lr: 0.0030\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 3s 62ms/step - loss: 0.1542 - acc: 0.9815 - trial: 369570.0000 - score: 0.9614 - val_loss: 0.2474 - val_acc: 0.9568 - val_trial: 369570.0000 - val_score: 0.9372 - lr: 0.0030\n",
      "Epoch 10/10\n",
      "52/53 [============================>.] - ETA: 0s - loss: 0.1481 - acc: 0.9830 - trial: 369570.0000 - score: 0.9629\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "53/53 [==============================] - 3s 66ms/step - loss: 0.1482 - acc: 0.9830 - trial: 369570.0000 - score: 0.9628 - val_loss: 0.2350 - val_acc: 0.9568 - val_trial: 369570.0000 - val_score: 0.9372 - lr: 0.0030\n",
      "\n",
      " It took 0.5833452304204305 minutes to train!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aqmodel = autoqk.get_best_model()\n",
    "print_qmodel_summary(aqmodel)\n",
    "\n",
    "# Train for the full epochs\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
    "]\n",
    "\n",
    "start = time.time()\n",
    "history = aqmodel.fit(train_data, epochs=n_epochs, validation_data=val_data, callbacks=callbacks, verbose=1)\n",
    "end = time.time()\n",
    "print('\\n It took {} minutes to train!\\n'.format((end - start) / 60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b0b2dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv_0 (QConv2D)            (None, 26, 26, 12)        108       \n",
      "                                                                 \n",
      " bn_conv_0 (BatchNormalizati  (None, 26, 26, 12)       48        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_act_0 (QActivation)    (None, 26, 26, 12)        0         \n",
      "                                                                 \n",
      " pool_0 (MaxPooling2D)       (None, 13, 13, 12)        0         \n",
      "                                                                 \n",
      " conv_1 (QConv2D)            (None, 11, 11, 8)         864       \n",
      "                                                                 \n",
      " bn_conv_1 (BatchNormalizati  (None, 11, 11, 8)        32        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_act_1 (QActivation)    (None, 11, 11, 8)         0         \n",
      "                                                                 \n",
      " pool_1 (MaxPooling2D)       (None, 5, 5, 8)           0         \n",
      "                                                                 \n",
      " conv_2 (QConv2D)            (None, 3, 3, 24)          1728      \n",
      "                                                                 \n",
      " bn_conv_2 (BatchNormalizati  (None, 3, 3, 24)         96        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_act_2 (QActivation)    (None, 3, 3, 24)          0         \n",
      "                                                                 \n",
      " pool_2 (MaxPooling2D)       (None, 1, 1, 24)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 24)                0         \n",
      "                                                                 \n",
      " dense_0 (QDense)            (None, 63)                1512      \n",
      "                                                                 \n",
      " bn_dense_0 (BatchNormalizat  (None, 63)               252       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_act_0 (QActivation)   (None, 63)                0         \n",
      "                                                                 \n",
      " dense_1 (QDense)            (None, 96)                6048      \n",
      "                                                                 \n",
      " bn_dense_1 (BatchNormalizat  (None, 96)               384       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_act_1 (QActivation)   (None, 96)                0         \n",
      "                                                                 \n",
      " output_dense (Dense)        (None, 10)                970       \n",
      "                                                                 \n",
      " output_softmax (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,042\n",
      "Trainable params: 11,636\n",
      "Non-trainable params: 406\n",
      "_________________________________________________________________\n",
      "conv_0               f=12 quantized_bits(8,0,1,alpha=1.0) \n",
      "bn_conv_0            is normal keras bn layer\n",
      "conv_act_0           quantized_relu(8,2)\n",
      "conv_1               f=8 quantized_bits(8,0,1,alpha=1.0) \n",
      "bn_conv_1            is normal keras bn layer\n",
      "conv_act_1           quantized_relu(8,2)\n",
      "conv_2               f=24 quantized_bits(8,0,1,alpha=1.0) \n",
      "bn_conv_2            is normal keras bn layer\n",
      "conv_act_2           quantized_relu(8,2)\n",
      "dense_0              u=63 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_dense_0           is normal keras bn layer\n",
      "dense_act_0          quantized_relu(3,1)\n",
      "dense_1              u=96 quantized_bits(2,0,1,alpha=1.0) \n",
      "bn_dense_1           is normal keras bn layer\n",
      "dense_act_1          quantized_relu(3,1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This model has some remnants from the optimization procedure attached to it, so let's define a new one\n",
    "aqmodel.save_weights(\"autoqkeras_cnn_weights.h5\")\n",
    "\n",
    "layers = [l for l in aqmodel.layers]\n",
    "x = layers[0].output\n",
    "for i in range(1, len(layers)):\n",
    "    x = layers[i](x)\n",
    "\n",
    "new_model = Model(inputs=[layers[0].input], outputs=[x])\n",
    "LOSS = tf.keras.losses.CategoricalCrossentropy()\n",
    "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=3e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "\n",
    "new_model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "new_model.summary()\n",
    "new_model.load_weights(\"autoqkeras_cnn_weights.h5\")\n",
    "\n",
    "print_qmodel_summary(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04672a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to: models/new_model.h5\n",
      "Serving 'models/new_model.h5' at http://localhost:55001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:55001\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f015c129b40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the model \n",
    "new_model_path = os.path.join(model_dir, \"new_model\")\n",
    "save_model(new_model, new_model_path)\n",
    "\n",
    "view_model(new_model_path+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200f12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 28, 28, 1]], output shape: [None, 28, 28, 1]\n",
      "Layer name: conv_0, layer type: QConv2D, input shapes: [[None, 28, 28, 1]], output shape: [None, 26, 26, 12]\n",
      "Layer name: bn_conv_0, layer type: BatchNormalization, input shapes: [[None, 26, 26, 12]], output shape: [None, 26, 26, 12]\n",
      "Layer name: conv_act_0, layer type: Activation, input shapes: [[None, 26, 26, 12]], output shape: [None, 26, 26, 12]\n",
      "Layer name: pool_0, layer type: MaxPooling2D, input shapes: [[None, 26, 26, 12]], output shape: [None, 13, 13, 12]\n",
      "Layer name: conv_1, layer type: QConv2D, input shapes: [[None, 13, 13, 12]], output shape: [None, 11, 11, 8]\n",
      "Layer name: bn_conv_1, layer type: BatchNormalization, input shapes: [[None, 11, 11, 8]], output shape: [None, 11, 11, 8]\n",
      "Layer name: conv_act_1, layer type: Activation, input shapes: [[None, 11, 11, 8]], output shape: [None, 11, 11, 8]\n",
      "Layer name: pool_1, layer type: MaxPooling2D, input shapes: [[None, 11, 11, 8]], output shape: [None, 5, 5, 8]\n",
      "Layer name: conv_2, layer type: QConv2D, input shapes: [[None, 5, 5, 8]], output shape: [None, 3, 3, 24]\n",
      "Layer name: bn_conv_2, layer type: BatchNormalization, input shapes: [[None, 3, 3, 24]], output shape: [None, 3, 3, 24]\n",
      "Layer name: conv_act_2, layer type: Activation, input shapes: [[None, 3, 3, 24]], output shape: [None, 3, 3, 24]\n",
      "Layer name: pool_2, layer type: MaxPooling2D, input shapes: [[None, 3, 3, 24]], output shape: [None, 1, 1, 24]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 1, 1, 24]], output shape: [None, 24]\n",
      "Layer name: dense_0, layer type: QDense, input shapes: [[None, 24]], output shape: [None, 63]\n",
      "Layer name: bn_dense_0, layer type: BatchNormalization, input shapes: [[None, 63]], output shape: [None, 63]\n",
      "Layer name: dense_act_0, layer type: Activation, input shapes: [[None, 63]], output shape: [None, 63]\n",
      "Layer name: dense_1, layer type: QDense, input shapes: [[None, 63]], output shape: [None, 96]\n",
      "Layer name: bn_dense_1, layer type: BatchNormalization, input shapes: [[None, 96]], output shape: [None, 96]\n",
      "Layer name: dense_act_1, layer type: Activation, input shapes: [[None, 96]], output shape: [None, 96]\n",
      "Layer name: output_dense, layer type: Dense, input shapes: [[None, 96]], output shape: [None, 10]\n",
      "Layer name: output_softmax, layer type: Softmax, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Model\n",
      "  Precision:         ap_fixed<16,6>\n",
      "  ReuseFactor:       2\n",
      "  Strategy:          Latency\n",
      "  BramFactor:        1000000000\n",
      "  TraceOutput:       False\n",
      "LayerName\n",
      "  input_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  conv_0\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        fixed<8,1,TRN,WRAP,0>\n",
      "      bias:          auto\n",
      "  conv_0_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  bn_conv_0\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      scale:         auto\n",
      "      bias:          auto\n",
      "  conv_act_0\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        ufixed<8,2,RND_CONV,SAT,0>\n",
      "  pool_0\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  conv_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        fixed<8,1,TRN,WRAP,0>\n",
      "      bias:          auto\n",
      "  conv_1_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  bn_conv_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      scale:         auto\n",
      "      bias:          auto\n",
      "  conv_act_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        ufixed<8,2,RND_CONV,SAT,0>\n",
      "  pool_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  conv_2\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        fixed<8,1,TRN,WRAP,0>\n",
      "      bias:          auto\n",
      "  conv_2_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  bn_conv_2\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      scale:         auto\n",
      "      bias:          auto\n",
      "  conv_act_2\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        ufixed<8,2,RND_CONV,SAT,0>\n",
      "  pool_2\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  flatten\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  dense_0\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        fixed<2,1,TRN,WRAP,0>\n",
      "      bias:          auto\n",
      "  dense_0_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  bn_dense_0\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      scale:         auto\n",
      "      bias:          auto\n",
      "  dense_act_0\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        ufixed<3,1,RND_CONV,SAT,0>\n",
      "  dense_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        fixed<2,1,TRN,WRAP,0>\n",
      "      bias:          auto\n",
      "  dense_1_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  bn_dense_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      scale:         auto\n",
      "      bias:          auto\n",
      "  dense_act_1\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        ufixed<3,1,RND_CONV,SAT,0>\n",
      "  output_dense\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "      weight:        auto\n",
      "      bias:          auto\n",
      "  output_dense_linear\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "  output_softmax\n",
      "    Trace:           False\n",
      "    Precision\n",
      "      result:        auto\n",
      "    Strategy:        Stable\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 28, 28, 1]], output shape: [None, 28, 28, 1]\n",
      "Layer name: conv_0, layer type: QConv2D, input shapes: [[None, 28, 28, 1]], output shape: [None, 26, 26, 12]\n",
      "Layer name: bn_conv_0, layer type: BatchNormalization, input shapes: [[None, 26, 26, 12]], output shape: [None, 26, 26, 12]\n",
      "Layer name: conv_act_0, layer type: Activation, input shapes: [[None, 26, 26, 12]], output shape: [None, 26, 26, 12]\n",
      "Layer name: pool_0, layer type: MaxPooling2D, input shapes: [[None, 26, 26, 12]], output shape: [None, 13, 13, 12]\n",
      "Layer name: conv_1, layer type: QConv2D, input shapes: [[None, 13, 13, 12]], output shape: [None, 11, 11, 8]\n",
      "Layer name: bn_conv_1, layer type: BatchNormalization, input shapes: [[None, 11, 11, 8]], output shape: [None, 11, 11, 8]\n",
      "Layer name: conv_act_1, layer type: Activation, input shapes: [[None, 11, 11, 8]], output shape: [None, 11, 11, 8]\n",
      "Layer name: pool_1, layer type: MaxPooling2D, input shapes: [[None, 11, 11, 8]], output shape: [None, 5, 5, 8]\n",
      "Layer name: conv_2, layer type: QConv2D, input shapes: [[None, 5, 5, 8]], output shape: [None, 3, 3, 24]\n",
      "Layer name: bn_conv_2, layer type: BatchNormalization, input shapes: [[None, 3, 3, 24]], output shape: [None, 3, 3, 24]\n",
      "Layer name: conv_act_2, layer type: Activation, input shapes: [[None, 3, 3, 24]], output shape: [None, 3, 3, 24]\n",
      "Layer name: pool_2, layer type: MaxPooling2D, input shapes: [[None, 3, 3, 24]], output shape: [None, 1, 1, 24]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 1, 1, 24]], output shape: [None, 24]\n",
      "Layer name: dense_0, layer type: QDense, input shapes: [[None, 24]], output shape: [None, 63]\n",
      "Layer name: bn_dense_0, layer type: BatchNormalization, input shapes: [[None, 63]], output shape: [None, 63]\n",
      "Layer name: dense_act_0, layer type: Activation, input shapes: [[None, 63]], output shape: [None, 63]\n",
      "Layer name: dense_1, layer type: QDense, input shapes: [[None, 63]], output shape: [None, 96]\n",
      "Layer name: bn_dense_1, layer type: BatchNormalization, input shapes: [[None, 96]], output shape: [None, 96]\n",
      "Layer name: dense_act_1, layer type: Activation, input shapes: [[None, 96]], output shape: [None, 96]\n",
      "Layer name: output_dense, layer type: Dense, input shapes: [[None, 96]], output shape: [None, 10]\n",
      "Layer name: output_softmax, layer type: Softmax, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "\n",
    "hls_config_aq = hls4ml.utils.config_from_keras_model(new_model, granularity='name')\n",
    "hls_config_aq['Model']['ReuseFactor'] = 8\n",
    "hls_config_aq['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "hls_config_aq['LayerName']['output_softmax']['Strategy'] = 'Stable'\n",
    "plotting.print_dict(hls_config_aq)\n",
    "\n",
    "cfg_aq = hls4ml.converters.create_config(backend='Vivado')\n",
    "cfg_aq['IOType'] = 'io_stream'  # Must set this if using CNNs!\n",
    "cfg_aq['HLSConfig'] = hls_config_aq\n",
    "cfg_aq['KerasModel'] = new_model\n",
    "cfg_aq['OutputDir'] = 'autoqkeras_cnn/'\n",
    "cfg_aq['XilinxPart'] = 'xczu5ev-sfvc784-1-i'\n",
    "\n",
    "hls_model_aq = hls4ml.converters.keras_to_hls(cfg_aq)\n",
    "hls_model_aq.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81eaf3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step\n",
      "Accuracy AutoQ Keras:  0.9631\n",
      "Accuracy AutoQ hls4ml: 0.9621\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predict_aq = aqmodel.predict(x_test)\n",
    "y_predict_hls4ml_aq = hls_model_aq.predict(np.ascontiguousarray(x_test))\n",
    "\n",
    "\n",
    "accuracy_keras = float(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_predict_aq, axis=1)))\n",
    "accuracy_hls4ml = float(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_predict_hls4ml_aq, axis=1)))\n",
    "\n",
    "print(\"Accuracy AutoQ Keras:  {}\".format(accuracy_keras))\n",
    "print(\"Accuracy AutoQ hls4ml: {}\".format(accuracy_hls4ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66357107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2020.1 (64-bit)\n",
      "  **** SW Build 2902540 on Wed May 27 19:54:35 MDT 2020\n",
      "  **** IP Build 2902112 on Wed May 27 22:43:36 MDT 2020\n",
      "    ** Copyright 1986-2020 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source /tools/Xilinx/Vivado/2020.1/scripts/vivado_hls/hls.tcl -notrace\n",
      "INFO: [HLS 200-10] Running '/tools/Xilinx/Vivado/2020.1/bin/unwrapped/lnx64.o/vivado_hls'\n",
      "INFO: [HLS 200-10] For user 'theodoros' on host 'ubuntu' (Linux_x86_64 version 5.4.0-150-generic) on Sun Apr 06 22:25:47 PDT 2025\n",
      "INFO: [HLS 200-10] On os Ubuntu 18.04.4 LTS\n",
      "INFO: [HLS 200-10] In directory '/home/theodoros/Documents/AI_ON_FPGA/autoqkeras_cnn'\n",
      "Sourcing Tcl script 'build_prj.tcl'\n",
      "INFO: [HLS 200-10] Creating and opening project '/home/theodoros/Documents/AI_ON_FPGA/autoqkeras_cnn/myproject_prj'.\n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'myproject_test.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'firmware/weights' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'tb_data' to the project\n",
      "INFO: [HLS 200-10] Creating and opening solution '/home/theodoros/Documents/AI_ON_FPGA/autoqkeras_cnn/myproject_prj/solution1'.\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 80.\n",
      "INFO: [HLS 200-10] Setting target device to 'xcvu13p-flga2577-2-e'\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with a period of 5ns.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with an uncertainty of 0.625ns.\n",
      "***** C/RTL SYNTHESIS *****\n",
      "INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject.cpp' ... \n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:52:75\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:52:79\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:56:88\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:56:92\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:68:79\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:68:83\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:72:88\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:72:92\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:84:83\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:84:88\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:88:91\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:88:96\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:101:79\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:101:84\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:105:93\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:105:98\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:113:79\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:113:84\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:117:93\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:117:98\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:125:84\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:125:89\n",
      "WARNING: [HLS 200-471] Dataflow form checks found 22 issue(s) in file firmware/myproject.cpp\n",
      "INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:18 ; elapsed = 00:00:43 . Memory (MB): peak = 1531.957 ; gain = 1099.754 ; free physical = 8191 ; free virtual = 12912\n",
      "INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:18 ; elapsed = 00:00:43 . Memory (MB): peak = 1531.957 ; gain = 1099.754 ; free physical = 8191 ; free virtual = 12912\n",
      "INFO: [HLS 200-10] Starting code transformations ...\n"
     ]
    }
   ],
   "source": [
    "synth = True\n",
    "if synth:\n",
    "    hls_model_aq.build(csim=False, synth=True, vsynth=True)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
